{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sb\n",
    "sb.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_experiment_start(line):\n",
    "    return line.startswith('evaluating for')\n",
    "\n",
    "def skip_n_experiments(input_file, experiment_num):\n",
    "    current_experiment = 0\n",
    "    while current_experiment < experiment_num:\n",
    "        line = input_file.readline()\n",
    "        if is_experiment_start(line):\n",
    "            current_experiment += 1\n",
    "            \n",
    "def get_metrics(line):\n",
    "    regexp = re.compile(r'[a-zA-Z0-9_]+\\: [0-9\\.]+')\n",
    "    result = {}\n",
    "    for metric_str in regexp.findall(line):\n",
    "        metric, value = metric_str.split(': ')\n",
    "        result[metric] = float(value)\n",
    "    return result\n",
    "    \n",
    "            \n",
    "def parse_experiment(experiment_log):\n",
    "    current_recommender = None\n",
    "    result = []\n",
    "    cnt =0\n",
    "    metrics = []\n",
    "    experiment_finished = True\n",
    "    for line in experiment_log:\n",
    "            if line.startswith('evaluating '):\n",
    "                current_recommender = line.split(' ')[1]\n",
    "                metrics = []\n",
    "                experiment_finished = False\n",
    "            if 'val_ndcg_at_40' in line:\n",
    "                    metrics.append(get_metrics(line))\n",
    "            try:\n",
    "                experiment_results = json.loads(line)\n",
    "                experiment_results['model_name'] =  current_recommender\n",
    "                experiment_results['metrics_history'] = metrics\n",
    "                result.append(experiment_results)\n",
    "                experiment_finished = True\n",
    "            except:\n",
    "                pass\n",
    "    if not experiment_finished:\n",
    "        experiment_results = {}\n",
    "        experiment_results['model_name'] =  current_recommender\n",
    "        experiment_results['metrics_history'] = metrics\n",
    "        result.append(experiment_results)\n",
    "    return result\n",
    "\n",
    "def get_data_from_logs(logfile, experiment_num):\n",
    "    current_experiment = 0\n",
    "    with open(logfile) as input_file:\n",
    "        skip_n_experiments(input_file, experiment_num)\n",
    "        experiment_log = []\n",
    "        for line in input_file:\n",
    "            if is_experiment_start(line):\n",
    "                break\n",
    "            else:\n",
    "                experiment_log.append(line.strip())\n",
    "        return parse_experiment(experiment_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_logs = './results/booking_config_ltr_2021_02_01T13_49_15/stdout'\n",
    "data = get_data_from_logs(experiment_logs, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data).set_index('model_name').sort_values('SPS@4')\n",
    "df.sort_values('ndcg@4')\n",
    "\n",
    "df['objective'] = [x.split('-')[-1] for x in df.index]\n",
    "df['booster'] = [x.split('-')[-2] for x in df.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_df = df[df.booster != 'rf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision@4</th>\n",
       "      <th>SPS@4</th>\n",
       "      <th>ndcg@4</th>\n",
       "      <th>ndcg@40</th>\n",
       "      <th>model_build_time</th>\n",
       "      <th>model_inference_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>objective</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mape</th>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.319160</td>\n",
       "      <td>0.235208</td>\n",
       "      <td>0.368449</td>\n",
       "      <td>414.962271</td>\n",
       "      <td>46.714759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_xendcg</th>\n",
       "      <td>0.109867</td>\n",
       "      <td>0.439470</td>\n",
       "      <td>0.335215</td>\n",
       "      <td>0.391287</td>\n",
       "      <td>177.777356</td>\n",
       "      <td>44.113322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression_l1</th>\n",
       "      <td>0.091108</td>\n",
       "      <td>0.364432</td>\n",
       "      <td>0.295119</td>\n",
       "      <td>0.407463</td>\n",
       "      <td>328.861916</td>\n",
       "      <td>48.308441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural</th>\n",
       "      <td>0.114995</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>0.348868</td>\n",
       "      <td>0.423816</td>\n",
       "      <td>4689.558168</td>\n",
       "      <td>149.008629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantile</th>\n",
       "      <td>0.119216</td>\n",
       "      <td>0.476863</td>\n",
       "      <td>0.366006</td>\n",
       "      <td>0.445621</td>\n",
       "      <td>367.461559</td>\n",
       "      <td>47.948216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poisson</th>\n",
       "      <td>0.117809</td>\n",
       "      <td>0.471236</td>\n",
       "      <td>0.360153</td>\n",
       "      <td>0.446560</td>\n",
       "      <td>415.057848</td>\n",
       "      <td>49.387735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fair</th>\n",
       "      <td>0.121436</td>\n",
       "      <td>0.485743</td>\n",
       "      <td>0.379631</td>\n",
       "      <td>0.456816</td>\n",
       "      <td>249.578643</td>\n",
       "      <td>47.422878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>huber</th>\n",
       "      <td>0.119529</td>\n",
       "      <td>0.478114</td>\n",
       "      <td>0.378881</td>\n",
       "      <td>0.459465</td>\n",
       "      <td>288.788421</td>\n",
       "      <td>47.901412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regression</th>\n",
       "      <td>0.124031</td>\n",
       "      <td>0.496123</td>\n",
       "      <td>0.386923</td>\n",
       "      <td>0.465070</td>\n",
       "      <td>276.585576</td>\n",
       "      <td>48.263079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambdarank</th>\n",
       "      <td>0.122718</td>\n",
       "      <td>0.490870</td>\n",
       "      <td>0.382891</td>\n",
       "      <td>0.465405</td>\n",
       "      <td>436.775603</td>\n",
       "      <td>50.535018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweedie</th>\n",
       "      <td>0.123937</td>\n",
       "      <td>0.495748</td>\n",
       "      <td>0.389150</td>\n",
       "      <td>0.469370</td>\n",
       "      <td>495.945984</td>\n",
       "      <td>52.490661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               precision@4     SPS@4    ndcg@4   ndcg@40  model_build_time  \\\n",
       "objective                                                                    \n",
       "mape              0.079790  0.319160  0.235208  0.368449        414.962271   \n",
       "rank_xendcg       0.109867  0.439470  0.335215  0.391287        177.777356   \n",
       "regression_l1     0.091108  0.364432  0.295119  0.407463        328.861916   \n",
       "Neural            0.114995  0.459980  0.348868  0.423816       4689.558168   \n",
       "quantile          0.119216  0.476863  0.366006  0.445621        367.461559   \n",
       "poisson           0.117809  0.471236  0.360153  0.446560        415.057848   \n",
       "fair              0.121436  0.485743  0.379631  0.456816        249.578643   \n",
       "huber             0.119529  0.478114  0.378881  0.459465        288.788421   \n",
       "regression        0.124031  0.496123  0.386923  0.465070        276.585576   \n",
       "lambdarank        0.122718  0.490870  0.382891  0.465405        436.775603   \n",
       "tweedie           0.123937  0.495748  0.389150  0.469370        495.945984   \n",
       "\n",
       "               model_inference_time  \n",
       "objective                            \n",
       "mape                      46.714759  \n",
       "rank_xendcg               44.113322  \n",
       "regression_l1             48.308441  \n",
       "Neural                   149.008629  \n",
       "quantile                  47.948216  \n",
       "poisson                   49.387735  \n",
       "fair                      47.422878  \n",
       "huber                     47.901412  \n",
       "regression                48.263079  \n",
       "lambdarank                50.535018  \n",
       "tweedie                   52.490661  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_df.groupby('objective').mean().sort_values('ndcg@40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision@4</th>\n",
       "      <th>SPS@4</th>\n",
       "      <th>ndcg@4</th>\n",
       "      <th>ndcg@40</th>\n",
       "      <th>model_build_time</th>\n",
       "      <th>model_inference_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>booster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>APREC</th>\n",
       "      <td>0.114995</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>0.348868</td>\n",
       "      <td>0.423816</td>\n",
       "      <td>4689.558168</td>\n",
       "      <td>149.008629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.112925</td>\n",
       "      <td>0.451701</td>\n",
       "      <td>0.343712</td>\n",
       "      <td>0.431480</td>\n",
       "      <td>174.829920</td>\n",
       "      <td>47.215277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dart</th>\n",
       "      <td>0.113082</td>\n",
       "      <td>0.452326</td>\n",
       "      <td>0.351424</td>\n",
       "      <td>0.434347</td>\n",
       "      <td>517.330149</td>\n",
       "      <td>50.706113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbdt</th>\n",
       "      <td>0.112806</td>\n",
       "      <td>0.451226</td>\n",
       "      <td>0.350411</td>\n",
       "      <td>0.440754</td>\n",
       "      <td>173.028886</td>\n",
       "      <td>45.910992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         precision@4     SPS@4    ndcg@4   ndcg@40  model_build_time  \\\n",
       "booster                                                                \n",
       "APREC       0.114995  0.459980  0.348868  0.423816       4689.558168   \n",
       "rf          0.112925  0.451701  0.343712  0.431480        174.829920   \n",
       "dart        0.113082  0.452326  0.351424  0.434347        517.330149   \n",
       "gbdt        0.112806  0.451226  0.350411  0.440754        173.028886   \n",
       "\n",
       "         model_inference_time  \n",
       "booster                        \n",
       "APREC              149.008629  \n",
       "rf                  47.215277  \n",
       "dart                50.706113  \n",
       "gbdt                45.910992  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('booster').mean().sort_values('ndcg@40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision@4</th>\n",
       "      <th>SPS@4</th>\n",
       "      <th>ndcg@4</th>\n",
       "      <th>ndcg@40</th>\n",
       "      <th>model_build_time</th>\n",
       "      <th>model_inference_time</th>\n",
       "      <th>model_metadata</th>\n",
       "      <th>metrics_history</th>\n",
       "      <th>objective</th>\n",
       "      <th>booster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-rank_xendcg</th>\n",
       "      <td>0.103114</td>\n",
       "      <td>0.412456</td>\n",
       "      <td>0.312533</td>\n",
       "      <td>0.341543</td>\n",
       "      <td>199.243688</td>\n",
       "      <td>44.128229</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>rank_xendcg</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-mape</th>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.319160</td>\n",
       "      <td>0.235216</td>\n",
       "      <td>0.368349</td>\n",
       "      <td>178.065018</td>\n",
       "      <td>44.276613</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>mape</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-mape</th>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.319160</td>\n",
       "      <td>0.235199</td>\n",
       "      <td>0.368550</td>\n",
       "      <td>651.859524</td>\n",
       "      <td>49.152905</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>mape</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-regression_l1</th>\n",
       "      <td>0.085605</td>\n",
       "      <td>0.342421</td>\n",
       "      <td>0.271751</td>\n",
       "      <td>0.396109</td>\n",
       "      <td>158.577517</td>\n",
       "      <td>45.518018</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>regression_l1</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-regression_l1</th>\n",
       "      <td>0.096611</td>\n",
       "      <td>0.386443</td>\n",
       "      <td>0.318486</td>\n",
       "      <td>0.418816</td>\n",
       "      <td>499.146315</td>\n",
       "      <td>51.098865</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>regression_l1</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>APREC-Neural</th>\n",
       "      <td>0.114995</td>\n",
       "      <td>0.459980</td>\n",
       "      <td>0.348868</td>\n",
       "      <td>0.423816</td>\n",
       "      <td>4689.558168</td>\n",
       "      <td>149.008629</td>\n",
       "      <td>{}</td>\n",
       "      <td>[{'loss': 0.9074, 'ndcg_at_40': 0.0247, 'val_l...</td>\n",
       "      <td>Neural</td>\n",
       "      <td>APREC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-poisson</th>\n",
       "      <td>0.114182</td>\n",
       "      <td>0.456728</td>\n",
       "      <td>0.347499</td>\n",
       "      <td>0.436310</td>\n",
       "      <td>163.943451</td>\n",
       "      <td>44.389229</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>poisson</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-rank_xendcg</th>\n",
       "      <td>0.116621</td>\n",
       "      <td>0.466483</td>\n",
       "      <td>0.357898</td>\n",
       "      <td>0.441032</td>\n",
       "      <td>156.311024</td>\n",
       "      <td>44.098415</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>rank_xendcg</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-quantile</th>\n",
       "      <td>0.118684</td>\n",
       "      <td>0.474737</td>\n",
       "      <td>0.362834</td>\n",
       "      <td>0.443134</td>\n",
       "      <td>160.153684</td>\n",
       "      <td>45.547329</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>quantile</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-quantile</th>\n",
       "      <td>0.119747</td>\n",
       "      <td>0.478989</td>\n",
       "      <td>0.369177</td>\n",
       "      <td>0.448107</td>\n",
       "      <td>574.769434</td>\n",
       "      <td>50.349103</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>quantile</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-fair</th>\n",
       "      <td>0.120810</td>\n",
       "      <td>0.483242</td>\n",
       "      <td>0.378695</td>\n",
       "      <td>0.455451</td>\n",
       "      <td>170.275032</td>\n",
       "      <td>45.655605</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>fair</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-poisson</th>\n",
       "      <td>0.121436</td>\n",
       "      <td>0.485743</td>\n",
       "      <td>0.372807</td>\n",
       "      <td>0.456809</td>\n",
       "      <td>666.172244</td>\n",
       "      <td>54.386240</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>poisson</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-huber</th>\n",
       "      <td>0.118872</td>\n",
       "      <td>0.475488</td>\n",
       "      <td>0.376669</td>\n",
       "      <td>0.457993</td>\n",
       "      <td>412.572644</td>\n",
       "      <td>50.875934</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>huber</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-fair</th>\n",
       "      <td>0.122061</td>\n",
       "      <td>0.488244</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.458182</td>\n",
       "      <td>328.882253</td>\n",
       "      <td>49.190151</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>fair</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-regression</th>\n",
       "      <td>0.122749</td>\n",
       "      <td>0.490995</td>\n",
       "      <td>0.379060</td>\n",
       "      <td>0.458394</td>\n",
       "      <td>383.866414</td>\n",
       "      <td>49.509755</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>regression</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-huber</th>\n",
       "      <td>0.120185</td>\n",
       "      <td>0.480740</td>\n",
       "      <td>0.381093</td>\n",
       "      <td>0.460937</td>\n",
       "      <td>165.004199</td>\n",
       "      <td>44.926889</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>huber</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-lambdarank</th>\n",
       "      <td>0.122311</td>\n",
       "      <td>0.489245</td>\n",
       "      <td>0.381914</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>191.917872</td>\n",
       "      <td>46.440436</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>lambdarank</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-lambdarank</th>\n",
       "      <td>0.123124</td>\n",
       "      <td>0.492496</td>\n",
       "      <td>0.383868</td>\n",
       "      <td>0.467082</td>\n",
       "      <td>681.633334</td>\n",
       "      <td>54.629600</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>lambdarank</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-dart-tweedie</th>\n",
       "      <td>0.123312</td>\n",
       "      <td>0.493247</td>\n",
       "      <td>0.385871</td>\n",
       "      <td>0.467993</td>\n",
       "      <td>775.155641</td>\n",
       "      <td>53.740344</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>tweedie</td>\n",
       "      <td>dart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-tweedie</th>\n",
       "      <td>0.124562</td>\n",
       "      <td>0.498249</td>\n",
       "      <td>0.392429</td>\n",
       "      <td>0.470747</td>\n",
       "      <td>216.736328</td>\n",
       "      <td>51.240979</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>tweedie</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lightgbm-gbdt-regression</th>\n",
       "      <td>0.125313</td>\n",
       "      <td>0.501251</td>\n",
       "      <td>0.394785</td>\n",
       "      <td>0.471747</td>\n",
       "      <td>169.304737</td>\n",
       "      <td>47.016404</td>\n",
       "      <td>{}</td>\n",
       "      <td>[]</td>\n",
       "      <td>regression</td>\n",
       "      <td>gbdt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             precision@4     SPS@4    ndcg@4   ndcg@40  \\\n",
       "model_name                                                               \n",
       "Lightgbm-dart-rank_xendcg       0.103114  0.412456  0.312533  0.341543   \n",
       "Lightgbm-gbdt-mape              0.079790  0.319160  0.235216  0.368349   \n",
       "Lightgbm-dart-mape              0.079790  0.319160  0.235199  0.368550   \n",
       "Lightgbm-gbdt-regression_l1     0.085605  0.342421  0.271751  0.396109   \n",
       "Lightgbm-dart-regression_l1     0.096611  0.386443  0.318486  0.418816   \n",
       "APREC-Neural                    0.114995  0.459980  0.348868  0.423816   \n",
       "Lightgbm-gbdt-poisson           0.114182  0.456728  0.347499  0.436310   \n",
       "Lightgbm-gbdt-rank_xendcg       0.116621  0.466483  0.357898  0.441032   \n",
       "Lightgbm-gbdt-quantile          0.118684  0.474737  0.362834  0.443134   \n",
       "Lightgbm-dart-quantile          0.119747  0.478989  0.369177  0.448107   \n",
       "Lightgbm-gbdt-fair              0.120810  0.483242  0.378695  0.455451   \n",
       "Lightgbm-dart-poisson           0.121436  0.485743  0.372807  0.456809   \n",
       "Lightgbm-dart-huber             0.118872  0.475488  0.376669  0.457993   \n",
       "Lightgbm-dart-fair              0.122061  0.488244  0.380567  0.458182   \n",
       "Lightgbm-dart-regression        0.122749  0.490995  0.379060  0.458394   \n",
       "Lightgbm-gbdt-huber             0.120185  0.480740  0.381093  0.460937   \n",
       "Lightgbm-gbdt-lambdarank        0.122311  0.489245  0.381914  0.463727   \n",
       "Lightgbm-dart-lambdarank        0.123124  0.492496  0.383868  0.467082   \n",
       "Lightgbm-dart-tweedie           0.123312  0.493247  0.385871  0.467993   \n",
       "Lightgbm-gbdt-tweedie           0.124562  0.498249  0.392429  0.470747   \n",
       "Lightgbm-gbdt-regression        0.125313  0.501251  0.394785  0.471747   \n",
       "\n",
       "                             model_build_time  model_inference_time  \\\n",
       "model_name                                                            \n",
       "Lightgbm-dart-rank_xendcg          199.243688             44.128229   \n",
       "Lightgbm-gbdt-mape                 178.065018             44.276613   \n",
       "Lightgbm-dart-mape                 651.859524             49.152905   \n",
       "Lightgbm-gbdt-regression_l1        158.577517             45.518018   \n",
       "Lightgbm-dart-regression_l1        499.146315             51.098865   \n",
       "APREC-Neural                      4689.558168            149.008629   \n",
       "Lightgbm-gbdt-poisson              163.943451             44.389229   \n",
       "Lightgbm-gbdt-rank_xendcg          156.311024             44.098415   \n",
       "Lightgbm-gbdt-quantile             160.153684             45.547329   \n",
       "Lightgbm-dart-quantile             574.769434             50.349103   \n",
       "Lightgbm-gbdt-fair                 170.275032             45.655605   \n",
       "Lightgbm-dart-poisson              666.172244             54.386240   \n",
       "Lightgbm-dart-huber                412.572644             50.875934   \n",
       "Lightgbm-dart-fair                 328.882253             49.190151   \n",
       "Lightgbm-dart-regression           383.866414             49.509755   \n",
       "Lightgbm-gbdt-huber                165.004199             44.926889   \n",
       "Lightgbm-gbdt-lambdarank           191.917872             46.440436   \n",
       "Lightgbm-dart-lambdarank           681.633334             54.629600   \n",
       "Lightgbm-dart-tweedie              775.155641             53.740344   \n",
       "Lightgbm-gbdt-tweedie              216.736328             51.240979   \n",
       "Lightgbm-gbdt-regression           169.304737             47.016404   \n",
       "\n",
       "                            model_metadata  \\\n",
       "model_name                                   \n",
       "Lightgbm-dart-rank_xendcg               {}   \n",
       "Lightgbm-gbdt-mape                      {}   \n",
       "Lightgbm-dart-mape                      {}   \n",
       "Lightgbm-gbdt-regression_l1             {}   \n",
       "Lightgbm-dart-regression_l1             {}   \n",
       "APREC-Neural                            {}   \n",
       "Lightgbm-gbdt-poisson                   {}   \n",
       "Lightgbm-gbdt-rank_xendcg               {}   \n",
       "Lightgbm-gbdt-quantile                  {}   \n",
       "Lightgbm-dart-quantile                  {}   \n",
       "Lightgbm-gbdt-fair                      {}   \n",
       "Lightgbm-dart-poisson                   {}   \n",
       "Lightgbm-dart-huber                     {}   \n",
       "Lightgbm-dart-fair                      {}   \n",
       "Lightgbm-dart-regression                {}   \n",
       "Lightgbm-gbdt-huber                     {}   \n",
       "Lightgbm-gbdt-lambdarank                {}   \n",
       "Lightgbm-dart-lambdarank                {}   \n",
       "Lightgbm-dart-tweedie                   {}   \n",
       "Lightgbm-gbdt-tweedie                   {}   \n",
       "Lightgbm-gbdt-regression                {}   \n",
       "\n",
       "                                                               metrics_history  \\\n",
       "model_name                                                                       \n",
       "Lightgbm-dart-rank_xendcg                                                   []   \n",
       "Lightgbm-gbdt-mape                                                          []   \n",
       "Lightgbm-dart-mape                                                          []   \n",
       "Lightgbm-gbdt-regression_l1                                                 []   \n",
       "Lightgbm-dart-regression_l1                                                 []   \n",
       "APREC-Neural                 [{'loss': 0.9074, 'ndcg_at_40': 0.0247, 'val_l...   \n",
       "Lightgbm-gbdt-poisson                                                       []   \n",
       "Lightgbm-gbdt-rank_xendcg                                                   []   \n",
       "Lightgbm-gbdt-quantile                                                      []   \n",
       "Lightgbm-dart-quantile                                                      []   \n",
       "Lightgbm-gbdt-fair                                                          []   \n",
       "Lightgbm-dart-poisson                                                       []   \n",
       "Lightgbm-dart-huber                                                         []   \n",
       "Lightgbm-dart-fair                                                          []   \n",
       "Lightgbm-dart-regression                                                    []   \n",
       "Lightgbm-gbdt-huber                                                         []   \n",
       "Lightgbm-gbdt-lambdarank                                                    []   \n",
       "Lightgbm-dart-lambdarank                                                    []   \n",
       "Lightgbm-dart-tweedie                                                       []   \n",
       "Lightgbm-gbdt-tweedie                                                       []   \n",
       "Lightgbm-gbdt-regression                                                    []   \n",
       "\n",
       "                                 objective booster  \n",
       "model_name                                          \n",
       "Lightgbm-dart-rank_xendcg      rank_xendcg    dart  \n",
       "Lightgbm-gbdt-mape                    mape    gbdt  \n",
       "Lightgbm-dart-mape                    mape    dart  \n",
       "Lightgbm-gbdt-regression_l1  regression_l1    gbdt  \n",
       "Lightgbm-dart-regression_l1  regression_l1    dart  \n",
       "APREC-Neural                        Neural   APREC  \n",
       "Lightgbm-gbdt-poisson              poisson    gbdt  \n",
       "Lightgbm-gbdt-rank_xendcg      rank_xendcg    gbdt  \n",
       "Lightgbm-gbdt-quantile            quantile    gbdt  \n",
       "Lightgbm-dart-quantile            quantile    dart  \n",
       "Lightgbm-gbdt-fair                    fair    gbdt  \n",
       "Lightgbm-dart-poisson              poisson    dart  \n",
       "Lightgbm-dart-huber                  huber    dart  \n",
       "Lightgbm-dart-fair                    fair    dart  \n",
       "Lightgbm-dart-regression        regression    dart  \n",
       "Lightgbm-gbdt-huber                  huber    gbdt  \n",
       "Lightgbm-gbdt-lambdarank        lambdarank    gbdt  \n",
       "Lightgbm-dart-lambdarank        lambdarank    dart  \n",
       "Lightgbm-dart-tweedie              tweedie    dart  \n",
       "Lightgbm-gbdt-tweedie              tweedie    gbdt  \n",
       "Lightgbm-gbdt-regression        regression    gbdt  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_df.sort_values('ndcg@40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{}\n",
      "{'loss': 0.9074, 'ndcg_at_40': 0.0247, 'val_loss': 0.5115, 'val_ndcg_at_40': 0.0357}\n",
      "{}\n",
      "{'loss': 0.4417, 'ndcg_at_40': 0.0229, 'val_loss': 0.1297, 'val_ndcg_at_40': 0.0331}\n",
      "{}\n",
      "{'loss': 0.11, 'ndcg_at_40': 0.0254, 'val_loss': 0.0422, 'val_ndcg_at_40': 0.0337}\n",
      "{}\n",
      "{'loss': 0.0565, 'ndcg_at_40': 0.0246, 'val_loss': 0.0933, 'val_ndcg_at_40': 0.0311}\n",
      "{}\n",
      "{'loss': 0.0969, 'ndcg_at_40': 0.0237, 'val_loss': 0.1215, 'val_ndcg_at_40': 0.0442}\n",
      "{}\n",
      "{'loss': 0.1289, 'ndcg_at_40': 0.0231, 'val_loss': 0.1544, 'val_ndcg_at_40': 0.0466}\n",
      "{}\n",
      "{'loss': 0.1586, 'ndcg_at_40': 0.0245, 'val_loss': 0.179, 'val_ndcg_at_40': 0.0565}\n",
      "{}\n",
      "{'loss': 0.1856, 'ndcg_at_40': 0.0221, 'val_loss': 0.2144, 'val_ndcg_at_40': 0.0449}\n",
      "{}\n",
      "{'loss': 0.2214, 'ndcg_at_40': 0.0237, 'val_loss': 0.2419, 'val_ndcg_at_40': 0.0355}\n",
      "{}\n",
      "{'loss': 0.2496, 'ndcg_at_40': 0.0242, 'val_loss': 0.2716, 'val_ndcg_at_40': 0.0425}\n",
      "{}\n",
      "{'loss': 0.2786, 'ndcg_at_40': 0.0237, 'val_loss': 0.3014, 'val_ndcg_at_40': 0.0458}\n",
      "{}\n",
      "{'loss': 0.3073, 'ndcg_at_40': 0.0249, 'val_loss': 0.3292, 'val_ndcg_at_40': 0.0471}\n",
      "{}\n",
      "{'loss': 0.3364, 'ndcg_at_40': 0.0225, 'val_loss': 0.3531, 'val_ndcg_at_40': 0.0257}\n",
      "{}\n",
      "{'loss': 0.3582, 'ndcg_at_40': 0.0232, 'val_loss': 0.377, 'val_ndcg_at_40': 0.0601}\n",
      "{}\n",
      "{'loss': 0.3834, 'ndcg_at_40': 0.0208, 'val_loss': 0.4024, 'val_ndcg_at_40': 0.0387}\n",
      "{}\n",
      "{'loss': 0.4092, 'ndcg_at_40': 0.0222, 'val_loss': 0.4308, 'val_ndcg_at_40': 0.0269}\n",
      "{}\n",
      "{'loss': 0.4363, 'ndcg_at_40': 0.0225, 'val_loss': 0.4501, 'val_ndcg_at_40': 0.0313}\n",
      "{}\n",
      "{'loss': 0.4541, 'ndcg_at_40': 0.0227, 'val_loss': 0.4659, 'val_ndcg_at_40': 0.036}\n",
      "{}\n",
      "{'loss': 0.4704, 'ndcg_at_40': 0.0251, 'val_loss': 0.4783, 'val_ndcg_at_40': 0.0369}\n",
      "{}\n",
      "{'loss': 0.4838, 'ndcg_at_40': 0.0203, 'val_loss': 0.5055, 'val_ndcg_at_40': 0.0517}\n",
      "{}\n",
      "{'loss': 0.513, 'ndcg_at_40': 0.0211, 'val_loss': 0.5343, 'val_ndcg_at_40': 0.0382}\n",
      "{}\n",
      "{'loss': 0.5397, 'ndcg_at_40': 0.021, 'val_loss': 0.5564, 'val_ndcg_at_40': 0.039}\n",
      "{}\n",
      "{'loss': 0.5632, 'ndcg_at_40': 0.0242, 'val_loss': 0.5849, 'val_ndcg_at_40': 0.0481}\n",
      "{}\n",
      "{'loss': 0.5904, 'ndcg_at_40': 0.0246, 'val_loss': 0.6082, 'val_ndcg_at_40': 0.029}\n",
      "{}\n",
      "{'loss': 0.6138, 'ndcg_at_40': 0.024, 'val_loss': 0.6291, 'val_ndcg_at_40': 0.0393}\n",
      "{}\n",
      "{'loss': 0.6354, 'ndcg_at_40': 0.0217, 'val_loss': 0.6555, 'val_ndcg_at_40': 0.066}\n",
      "{}\n",
      "{'loss': 0.6596, 'ndcg_at_40': 0.0237, 'val_loss': 0.6736, 'val_ndcg_at_40': 0.0574}\n",
      "{}\n",
      "{'loss': 0.6773, 'ndcg_at_40': 0.0245, 'val_loss': 0.6907, 'val_ndcg_at_40': 0.0732}\n",
      "{}\n",
      "{'loss': 0.6971, 'ndcg_at_40': 0.0218, 'val_loss': 0.7146, 'val_ndcg_at_40': 0.0745}\n",
      "{}\n",
      "{'loss': 0.7216, 'ndcg_at_40': 0.0222, 'val_loss': 0.7425, 'val_ndcg_at_40': 0.0513}\n",
      "{}\n",
      "{'loss': 0.7485, 'ndcg_at_40': 0.0246, 'val_loss': 0.7717, 'val_ndcg_at_40': 0.047}\n",
      "{}\n",
      "{'loss': 0.7799, 'ndcg_at_40': 0.0224, 'val_loss': 0.7992, 'val_ndcg_at_40': 0.0752}\n",
      "{}\n",
      "{'loss': 0.804, 'ndcg_at_40': 0.0254, 'val_loss': 0.8185, 'val_ndcg_at_40': 0.0808}\n",
      "{}\n",
      "{'loss': 0.8234, 'ndcg_at_40': 0.0255, 'val_loss': 0.8386, 'val_ndcg_at_40': 0.1169}\n",
      "{}\n",
      "{'loss': 0.8447, 'ndcg_at_40': 0.0256, 'val_loss': 0.8577, 'val_ndcg_at_40': 0.0691}\n",
      "{}\n",
      "{'loss': 0.8621, 'ndcg_at_40': 0.0265, 'val_loss': 0.8803, 'val_ndcg_at_40': 0.0964}\n",
      "{}\n",
      "{'loss': 0.887, 'ndcg_at_40': 0.0283, 'val_loss': 0.9077, 'val_ndcg_at_40': 0.1025}\n",
      "{}\n",
      "{'loss': 0.915, 'ndcg_at_40': 0.0288, 'val_loss': 0.9354, 'val_ndcg_at_40': 0.1012}\n",
      "{}\n",
      "{'loss': 0.9405, 'ndcg_at_40': 0.0256, 'val_loss': 0.9566, 'val_ndcg_at_40': 0.076}\n",
      "{}\n",
      "{'loss': 0.9643, 'ndcg_at_40': 0.0267, 'val_loss': 0.9868, 'val_ndcg_at_40': 0.0893}\n",
      "{}\n",
      "{'loss': 0.9929, 'ndcg_at_40': 0.0277, 'val_loss': 1.0152, 'val_ndcg_at_40': 0.1299}\n",
      "{}\n",
      "{'loss': 1.0216, 'ndcg_at_40': 0.0306, 'val_loss': 1.0464, 'val_ndcg_at_40': 0.1168}\n",
      "{}\n",
      "{'loss': 1.0533, 'ndcg_at_40': 0.0284, 'val_loss': 1.0691, 'val_ndcg_at_40': 0.0981}\n",
      "{}\n",
      "{'loss': 1.0747, 'ndcg_at_40': 0.0302, 'val_loss': 1.0942, 'val_ndcg_at_40': 0.1058}\n",
      "{}\n",
      "{'loss': 1.0994, 'ndcg_at_40': 0.0303, 'val_loss': 1.115, 'val_ndcg_at_40': 0.1094}\n",
      "{}\n",
      "{'loss': 1.1226, 'ndcg_at_40': 0.0344, 'val_loss': 1.1506, 'val_ndcg_at_40': 0.0966}\n",
      "{}\n",
      "{'loss': 1.1594, 'ndcg_at_40': 0.0309, 'val_loss': 1.1855, 'val_ndcg_at_40': 0.123}\n",
      "{}\n",
      "{'loss': 1.1935, 'ndcg_at_40': 0.0324, 'val_loss': 1.2187, 'val_ndcg_at_40': 0.1121}\n",
      "{}\n",
      "{'loss': 1.2233, 'ndcg_at_40': 0.036, 'val_loss': 1.2383, 'val_ndcg_at_40': 0.1063}\n",
      "{}\n",
      "{'loss': 1.2453, 'ndcg_at_40': 0.0347, 'val_loss': 1.2669, 'val_ndcg_at_40': 0.1199}\n",
      "{}\n",
      "{'loss': 1.2768, 'ndcg_at_40': 0.0373, 'val_loss': 1.2999, 'val_ndcg_at_40': 0.1282}\n",
      "{}\n",
      "{'loss': 1.306, 'ndcg_at_40': 0.0394, 'val_loss': 1.3235, 'val_ndcg_at_40': 0.1165}\n",
      "{}\n",
      "{'loss': 1.3287, 'ndcg_at_40': 0.0384, 'val_loss': 1.3481, 'val_ndcg_at_40': 0.1356}\n",
      "{}\n",
      "{'loss': 1.3555, 'ndcg_at_40': 0.0429, 'val_loss': 1.3712, 'val_ndcg_at_40': 0.1333}\n",
      "{}\n",
      "{'loss': 1.3747, 'ndcg_at_40': 0.0468, 'val_loss': 1.3895, 'val_ndcg_at_40': 0.1445}\n",
      "{}\n",
      "{'loss': 1.3969, 'ndcg_at_40': 0.0454, 'val_loss': 1.4196, 'val_ndcg_at_40': 0.1145}\n",
      "{}\n",
      "{'loss': 1.4264, 'ndcg_at_40': 0.0444, 'val_loss': 1.4417, 'val_ndcg_at_40': 0.1162}\n",
      "{}\n",
      "{'loss': 1.4467, 'ndcg_at_40': 0.0464, 'val_loss': 1.4603, 'val_ndcg_at_40': 0.124}\n",
      "{}\n",
      "{'loss': 1.4652, 'ndcg_at_40': 0.0469, 'val_loss': 1.4838, 'val_ndcg_at_40': 0.1357}\n",
      "{}\n",
      "{'loss': 1.492, 'ndcg_at_40': 0.0493, 'val_loss': 1.517, 'val_ndcg_at_40': 0.1363}\n",
      "{}\n",
      "{'loss': 1.5208, 'ndcg_at_40': 0.0501, 'val_loss': 1.5298, 'val_ndcg_at_40': 0.1252}\n",
      "{}\n",
      "{'loss': 1.5325, 'ndcg_at_40': 0.0503, 'val_loss': 1.5442, 'val_ndcg_at_40': 0.1337}\n",
      "{}\n",
      "{'loss': 1.5492, 'ndcg_at_40': 0.048, 'val_loss': 1.5634, 'val_ndcg_at_40': 0.156}\n",
      "{}\n",
      "{'loss': 1.565, 'ndcg_at_40': 0.054, 'val_loss': 1.5736, 'val_ndcg_at_40': 0.173}\n",
      "{}\n",
      "{'loss': 1.5767, 'ndcg_at_40': 0.0582, 'val_loss': 1.5871, 'val_ndcg_at_40': 0.1362}\n",
      "{}\n",
      "{'loss': 1.5888, 'ndcg_at_40': 0.054, 'val_loss': 1.5975, 'val_ndcg_at_40': 0.1622}\n",
      "{}\n",
      "{'loss': 1.5992, 'ndcg_at_40': 0.0551, 'val_loss': 1.6082, 'val_ndcg_at_40': 0.1617}\n",
      "{}\n",
      "{'loss': 1.6132, 'ndcg_at_40': 0.0561, 'val_loss': 1.6285, 'val_ndcg_at_40': 0.1561}\n",
      "{}\n",
      "{'loss': 1.6324, 'ndcg_at_40': 0.056, 'val_loss': 1.6419, 'val_ndcg_at_40': 0.1809}\n",
      "{}\n",
      "{'loss': 1.6453, 'ndcg_at_40': 0.0652, 'val_loss': 1.6508, 'val_ndcg_at_40': 0.175}\n",
      "{}\n",
      "{'loss': 1.6563, 'ndcg_at_40': 0.0669, 'val_loss': 1.6679, 'val_ndcg_at_40': 0.1455}\n",
      "{}\n",
      "{'loss': 1.6713, 'ndcg_at_40': 0.0644, 'val_loss': 1.679, 'val_ndcg_at_40': 0.1621}\n",
      "{}\n",
      "{'loss': 1.6828, 'ndcg_at_40': 0.0626, 'val_loss': 1.6955, 'val_ndcg_at_40': 0.1755}\n",
      "{}\n",
      "{'loss': 1.6985, 'ndcg_at_40': 0.0691, 'val_loss': 1.7133, 'val_ndcg_at_40': 0.1938}\n",
      "{}\n",
      "{'loss': 1.7189, 'ndcg_at_40': 0.0697, 'val_loss': 1.7321, 'val_ndcg_at_40': 0.1614}\n",
      "{}\n",
      "{'loss': 1.7382, 'ndcg_at_40': 0.0804, 'val_loss': 1.7587, 'val_ndcg_at_40': 0.1728}\n",
      "{}\n",
      "{'loss': 1.7631, 'ndcg_at_40': 0.0758, 'val_loss': 1.7778, 'val_ndcg_at_40': 0.1519}\n",
      "{}\n",
      "{'loss': 1.7843, 'ndcg_at_40': 0.0791, 'val_loss': 1.8022, 'val_ndcg_at_40': 0.1714}\n",
      "{}\n",
      "{'loss': 1.8043, 'ndcg_at_40': 0.0857, 'val_loss': 1.8131, 'val_ndcg_at_40': 0.191}\n",
      "{}\n",
      "{'loss': 1.8161, 'ndcg_at_40': 0.0745, 'val_loss': 1.8272, 'val_ndcg_at_40': 0.1893}\n",
      "{}\n",
      "{'loss': 1.8293, 'ndcg_at_40': 0.0834, 'val_loss': 1.8342, 'val_ndcg_at_40': 0.1885}\n",
      "{}\n",
      "{'loss': 1.84, 'ndcg_at_40': 0.0831, 'val_loss': 1.8587, 'val_ndcg_at_40': 0.1597}\n",
      "{}\n",
      "{'loss': 1.8657, 'ndcg_at_40': 0.0952, 'val_loss': 1.8799, 'val_ndcg_at_40': 0.2038}\n",
      "{}\n",
      "{'loss': 1.8857, 'ndcg_at_40': 0.0976, 'val_loss': 1.8984, 'val_ndcg_at_40': 0.2025}\n",
      "{}\n",
      "{'loss': 1.9052, 'ndcg_at_40': 0.0941, 'val_loss': 1.9309, 'val_ndcg_at_40': 0.2062}\n",
      "{}\n",
      "{'loss': 1.9391, 'ndcg_at_40': 0.104, 'val_loss': 1.9562, 'val_ndcg_at_40': 0.1838}\n",
      "{}\n",
      "{'loss': 1.9606, 'ndcg_at_40': 0.1003, 'val_loss': 1.9713, 'val_ndcg_at_40': 0.181}\n",
      "{}\n",
      "{'loss': 1.9747, 'ndcg_at_40': 0.1052, 'val_loss': 1.9853, 'val_ndcg_at_40': 0.2395}\n",
      "{}\n",
      "{'loss': 1.9882, 'ndcg_at_40': 0.1066, 'val_loss': 1.9986, 'val_ndcg_at_40': 0.2301}\n",
      "{}\n",
      "{'loss': 2.0037, 'ndcg_at_40': 0.1261, 'val_loss': 2.025, 'val_ndcg_at_40': 0.2805}\n",
      "{}\n",
      "{'loss': 2.0309, 'ndcg_at_40': 0.1372, 'val_loss': 2.044, 'val_ndcg_at_40': 0.2676}\n",
      "{}\n",
      "{'loss': 2.0471, 'ndcg_at_40': 0.1501, 'val_loss': 2.0571, 'val_ndcg_at_40': 0.2545}\n",
      "{}\n",
      "{'loss': 2.0593, 'ndcg_at_40': 0.15, 'val_loss': 2.0739, 'val_ndcg_at_40': 0.2714}\n",
      "{}\n",
      "{'loss': 2.0831, 'ndcg_at_40': 0.1462, 'val_loss': 2.1047, 'val_ndcg_at_40': 0.2742}\n",
      "{}\n",
      "{'loss': 2.1107, 'ndcg_at_40': 0.1455, 'val_loss': 2.122, 'val_ndcg_at_40': 0.2387}\n",
      "{}\n",
      "{'loss': 2.1224, 'ndcg_at_40': 0.1474, 'val_loss': 2.1306, 'val_ndcg_at_40': 0.2618}\n",
      "{}\n",
      "{'loss': 2.1332, 'ndcg_at_40': 0.1631, 'val_loss': 2.1498, 'val_ndcg_at_40': 0.2707}\n",
      "{}\n",
      "{'loss': 2.153, 'ndcg_at_40': 0.1497, 'val_loss': 2.1674, 'val_ndcg_at_40': 0.2802}\n",
      "{}\n",
      "{'loss': 2.1754, 'ndcg_at_40': 0.1599, 'val_loss': 2.1945, 'val_ndcg_at_40': 0.2957}\n",
      "{}\n",
      "{'loss': 2.1973, 'ndcg_at_40': 0.1639, 'val_loss': 2.2129, 'val_ndcg_at_40': 0.2418}\n",
      "{}\n",
      "{'loss': 2.218, 'ndcg_at_40': 0.1595, 'val_loss': 2.2286, 'val_ndcg_at_40': 0.2976}\n",
      "{}\n",
      "{'loss': 2.2322, 'ndcg_at_40': 0.164, 'val_loss': 2.2428, 'val_ndcg_at_40': 0.2818}\n",
      "{}\n",
      "{'loss': 2.2419, 'ndcg_at_40': 0.1551, 'val_loss': 2.2406, 'val_ndcg_at_40': 0.2941}\n",
      "{}\n",
      "{'loss': 2.2431, 'ndcg_at_40': 0.158, 'val_loss': 2.2568, 'val_ndcg_at_40': 0.2772}\n",
      "{}\n",
      "{'loss': 2.2601, 'ndcg_at_40': 0.168, 'val_loss': 2.2673, 'val_ndcg_at_40': 0.2882}\n",
      "{}\n",
      "{'loss': 2.2712, 'ndcg_at_40': 0.1571, 'val_loss': 2.2796, 'val_ndcg_at_40': 0.3029}\n",
      "{}\n",
      "{'loss': 2.2818, 'ndcg_at_40': 0.1543, 'val_loss': 2.2904, 'val_ndcg_at_40': 0.2898}\n",
      "{}\n",
      "{'loss': 2.295, 'ndcg_at_40': 0.1701, 'val_loss': 2.3034, 'val_ndcg_at_40': 0.31}\n",
      "{}\n",
      "{'loss': 2.3035, 'ndcg_at_40': 0.1629, 'val_loss': 2.3019, 'val_ndcg_at_40': 0.2607}\n",
      "{}\n",
      "{'loss': 2.3011, 'ndcg_at_40': 0.1587, 'val_loss': 2.293, 'val_ndcg_at_40': 0.2971}\n",
      "{}\n",
      "{'loss': 2.2925, 'ndcg_at_40': 0.1628, 'val_loss': 2.292, 'val_ndcg_at_40': 0.3112}\n",
      "{}\n",
      "{'loss': 2.292, 'ndcg_at_40': 0.1588, 'val_loss': 2.2905, 'val_ndcg_at_40': 0.2919}\n",
      "{}\n",
      "{'loss': 2.2889, 'ndcg_at_40': 0.1666, 'val_loss': 2.2891, 'val_ndcg_at_40': 0.3034}\n",
      "{}\n",
      "{'loss': 2.2858, 'ndcg_at_40': 0.1612, 'val_loss': 2.2777, 'val_ndcg_at_40': 0.276}\n",
      "{}\n",
      "{'loss': 2.2775, 'ndcg_at_40': 0.1651, 'val_loss': 2.2757, 'val_ndcg_at_40': 0.3089}\n",
      "{}\n",
      "{'loss': 2.2724, 'ndcg_at_40': 0.1686, 'val_loss': 2.2654, 'val_ndcg_at_40': 0.3069}\n",
      "{}\n",
      "{'loss': 2.264, 'ndcg_at_40': 0.1543, 'val_loss': 2.2569, 'val_ndcg_at_40': 0.3048}\n",
      "{}\n",
      "{'loss': 2.2558, 'ndcg_at_40': 0.1576, 'val_loss': 2.2557, 'val_ndcg_at_40': 0.2814}\n",
      "{}\n",
      "{'loss': 2.2519, 'ndcg_at_40': 0.1538, 'val_loss': 2.2398, 'val_ndcg_at_40': 0.2565}\n",
      "{}\n",
      "{'loss': 2.2302, 'ndcg_at_40': 0.1317, 'val_loss': 1.9363, 'val_ndcg_at_40': 0.1081}\n",
      "{}\n",
      "{'loss': 2.0048, 'ndcg_at_40': 0.122, 'val_loss': 1.8839, 'val_ndcg_at_40': 0.0769}\n",
      "{}\n",
      "{'loss': 1.9121, 'ndcg_at_40': 0.1043, 'val_loss': 1.7865, 'val_ndcg_at_40': 0.1088}\n",
      "{}\n",
      "{'loss': 1.9368, 'ndcg_at_40': 0.1013, 'val_loss': 1.7655, 'val_ndcg_at_40': 0.1242}\n",
      "{}\n",
      "{'loss': 1.8577, 'ndcg_at_40': 0.0868, 'val_loss': 1.5308, 'val_ndcg_at_40': 0.1145}\n",
      "{}\n",
      "{'loss': 1.7653, 'ndcg_at_40': 0.0995, 'val_loss': 1.6163, 'val_ndcg_at_40': 0.1315}\n",
      "{}\n",
      "{'loss': 1.7779, 'ndcg_at_40': 0.101, 'val_loss': 1.6515, 'val_ndcg_at_40': 0.1074}\n",
      "{}\n",
      "{'loss': 1.7296, 'ndcg_at_40': 0.1044, 'val_loss': 1.68, 'val_ndcg_at_40': 0.1201}\n",
      "{}\n",
      "{'loss': 1.7314, 'ndcg_at_40': 0.102, 'val_loss': 1.662, 'val_ndcg_at_40': 0.1729}\n",
      "{}\n",
      "{'loss': 1.7239, 'ndcg_at_40': 0.1165, 'val_loss': 1.6636, 'val_ndcg_at_40': 0.1047}\n",
      "{}\n",
      "{'loss': 1.6843, 'ndcg_at_40': 0.1235, 'val_loss': 1.7604, 'val_ndcg_at_40': 0.0475}\n",
      "{}\n",
      "{'loss': 1.7528, 'ndcg_at_40': 0.1256, 'val_loss': 1.7118, 'val_ndcg_at_40': 0.0967}\n",
      "{}\n",
      "{'loss': 1.6683, 'ndcg_at_40': 0.1397, 'val_loss': 1.7782, 'val_ndcg_at_40': 0.0765}\n",
      "{}\n",
      "{'loss': 1.7323, 'ndcg_at_40': 0.1472, 'val_loss': 1.8223, 'val_ndcg_at_40': 0.0936}\n",
      "{}\n",
      "{'loss': 1.7362, 'ndcg_at_40': 0.15, 'val_loss': 1.8075, 'val_ndcg_at_40': 0.0889}\n",
      "{}\n",
      "{'loss': 1.7525, 'ndcg_at_40': 0.1545, 'val_loss': 1.8919, 'val_ndcg_at_40': 0.0733}\n",
      "{}\n",
      "{'loss': 1.734, 'ndcg_at_40': 0.1499, 'val_loss': 1.9084, 'val_ndcg_at_40': 0.2403}\n",
      "{}\n",
      "{'loss': 1.7957, 'ndcg_at_40': 0.1346, 'val_loss': 1.9017, 'val_ndcg_at_40': 0.0646}\n",
      "{}\n",
      "{'loss': 1.7864, 'ndcg_at_40': 0.1533, 'val_loss': 2.0094, 'val_ndcg_at_40': 0.0834}\n",
      "{}\n",
      "{'loss': 1.889, 'ndcg_at_40': 0.1659, 'val_loss': 1.9626, 'val_ndcg_at_40': 0.1025}\n",
      "{}\n",
      "{'loss': 1.8003, 'ndcg_at_40': 0.1743, 'val_loss': 2.092, 'val_ndcg_at_40': 0.1118}\n",
      "{}\n",
      "{'loss': 1.8976, 'ndcg_at_40': 0.1938, 'val_loss': 2.0261, 'val_ndcg_at_40': 0.099}\n",
      "{}\n",
      "{'loss': 1.8122, 'ndcg_at_40': 0.1699, 'val_loss': 1.9521, 'val_ndcg_at_40': 0.3411}\n",
      "{}\n",
      "{'loss': 1.7956, 'ndcg_at_40': 0.1892, 'val_loss': 2.0764, 'val_ndcg_at_40': 0.2103}\n",
      "{}\n",
      "{'loss': 1.8209, 'ndcg_at_40': 0.2203, 'val_loss': 2.2799, 'val_ndcg_at_40': 0.1692}\n",
      "{}\n",
      "{'loss': 1.8704, 'ndcg_at_40': 0.25, 'val_loss': 2.1087, 'val_ndcg_at_40': 0.1759}\n",
      "{}\n",
      "{'loss': 1.7527, 'ndcg_at_40': 0.2074, 'val_loss': 2.263, 'val_ndcg_at_40': 0.3998}\n",
      "{}\n",
      "{'loss': 1.9633, 'ndcg_at_40': 0.266, 'val_loss': 2.0224, 'val_ndcg_at_40': 0.157}\n",
      "{}\n",
      "{'loss': 1.8757, 'ndcg_at_40': 0.2332, 'val_loss': 2.315, 'val_ndcg_at_40': 0.235}\n",
      "{}\n",
      "{'loss': 1.8446, 'ndcg_at_40': 0.2616, 'val_loss': 2.3838, 'val_ndcg_at_40': 0.3836}\n",
      "{}\n",
      "{'loss': 2.0401, 'ndcg_at_40': 0.2997, 'val_loss': 2.2002, 'val_ndcg_at_40': 0.3471}\n",
      "{}\n",
      "{'loss': 2.0094, 'ndcg_at_40': 0.2967, 'val_loss': 2.2802, 'val_ndcg_at_40': 0.2389}\n",
      "{}\n",
      "{'loss': 1.9383, 'ndcg_at_40': 0.282, 'val_loss': 2.6392, 'val_ndcg_at_40': 0.2408}\n",
      "{}\n",
      "{'loss': 2.1578, 'ndcg_at_40': 0.301, 'val_loss': 2.4052, 'val_ndcg_at_40': 0.2375}\n",
      "{}\n",
      "{'loss': 1.9939, 'ndcg_at_40': 0.2973, 'val_loss': 2.573, 'val_ndcg_at_40': 0.4017}\n",
      "{}\n",
      "{'loss': 2.3417, 'ndcg_at_40': 0.3113, 'val_loss': 2.9809, 'val_ndcg_at_40': 0.4074}\n",
      "{}\n",
      "{'loss': 2.335, 'ndcg_at_40': 0.3126, 'val_loss': 2.9364, 'val_ndcg_at_40': 0.239}\n",
      "{}\n",
      "{'loss': 2.2607, 'ndcg_at_40': 0.3124, 'val_loss': 2.833, 'val_ndcg_at_40': 0.3931}\n",
      "{}\n",
      "{'loss': 2.3632, 'ndcg_at_40': 0.2999, 'val_loss': 2.9265, 'val_ndcg_at_40': 0.409}\n",
      "{}\n",
      "{'loss': 2.468, 'ndcg_at_40': 0.3153, 'val_loss': 3.166, 'val_ndcg_at_40': 0.4058}\n",
      "{}\n",
      "{'loss': 2.6362, 'ndcg_at_40': 0.3144, 'val_loss': 2.8036, 'val_ndcg_at_40': 0.3901}\n",
      "{}\n",
      "{'loss': 2.5603, 'ndcg_at_40': 0.3121, 'val_loss': 3.0473, 'val_ndcg_at_40': 0.3822}\n",
      "{}\n",
      "{'loss': 2.6398, 'ndcg_at_40': 0.3113, 'val_loss': 3.0393, 'val_ndcg_at_40': 0.3892}\n",
      "{}\n",
      "{'loss': 2.5612, 'ndcg_at_40': 0.3198, 'val_loss': 3.2668, 'val_ndcg_at_40': 0.4012}\n",
      "{}\n",
      "{'loss': 2.8173, 'ndcg_at_40': 0.3247, 'val_loss': 3.3712, 'val_ndcg_at_40': 0.3471}\n",
      "{}\n",
      "{'loss': 2.9052, 'ndcg_at_40': 0.3302, 'val_loss': 3.5106, 'val_ndcg_at_40': 0.4158}\n",
      "{}\n",
      "{'loss': 3.0706, 'ndcg_at_40': 0.3427, 'val_loss': 3.2907, 'val_ndcg_at_40': 0.2768}\n",
      "{}\n",
      "{'loss': 2.9426, 'ndcg_at_40': 0.3411, 'val_loss': 3.6755, 'val_ndcg_at_40': 0.4047}\n",
      "{}\n",
      "{'loss': 3.1512, 'ndcg_at_40': 0.349, 'val_loss': 3.6499, 'val_ndcg_at_40': 0.3002}\n",
      "{}\n",
      "{'loss': 3.1344, 'ndcg_at_40': 0.3412, 'val_loss': 3.7462, 'val_ndcg_at_40': 0.2832}\n",
      "{}\n",
      "{'loss': 3.2657, 'ndcg_at_40': 0.3453, 'val_loss': 3.8416, 'val_ndcg_at_40': 0.2605}\n",
      "{}\n",
      "{'loss': 3.2732, 'ndcg_at_40': 0.3252, 'val_loss': 4.008, 'val_ndcg_at_40': 0.3669}\n",
      "{}\n",
      "{'loss': 3.4154, 'ndcg_at_40': 0.3422, 'val_loss': 4.1624, 'val_ndcg_at_40': 0.3963}\n",
      "{}\n",
      "{'loss': 3.5485, 'ndcg_at_40': 0.3523, 'val_loss': 4.2532, 'val_ndcg_at_40': 0.3312}\n",
      "{}\n",
      "{'loss': 3.5349, 'ndcg_at_40': 0.3335, 'val_loss': 4.2895, 'val_ndcg_at_40': 0.2854}\n",
      "{}\n",
      "{'loss': 3.5134, 'ndcg_at_40': 0.3203, 'val_loss': 4.3461, 'val_ndcg_at_40': 0.3199}\n",
      "{}\n",
      "{'loss': 3.6754, 'ndcg_at_40': 0.3353, 'val_loss': 4.0456, 'val_ndcg_at_40': 0.3555}\n",
      "{}\n",
      "{'loss': 3.5222, 'ndcg_at_40': 0.3473, 'val_loss': 4.3579, 'val_ndcg_at_40': 0.4119}\n",
      "{}\n",
      "{'loss': 3.8261, 'ndcg_at_40': 0.3546, 'val_loss': 4.4688, 'val_ndcg_at_40': 0.3741}\n",
      "{}\n",
      "{'loss': 3.8008, 'ndcg_at_40': 0.3515, 'val_loss': 4.7351, 'val_ndcg_at_40': 0.4179}\n",
      "{}\n",
      "{'loss': 3.9613, 'ndcg_at_40': 0.3539, 'val_loss': 4.4943, 'val_ndcg_at_40': 0.4069}\n",
      "{}\n",
      "{'loss': 3.9111, 'ndcg_at_40': 0.3415, 'val_loss': 4.4796, 'val_ndcg_at_40': 0.3986}\n",
      "{}\n",
      "{'loss': 3.8256, 'ndcg_at_40': 0.3259, 'val_loss': 4.5453, 'val_ndcg_at_40': 0.4152}\n",
      "{}\n",
      "{'loss': 3.9163, 'ndcg_at_40': 0.3488, 'val_loss': 4.6622, 'val_ndcg_at_40': 0.416}\n",
      "{}\n",
      "{'loss': 3.8188, 'ndcg_at_40': 0.3405, 'val_loss': 4.6985, 'val_ndcg_at_40': 0.4166}\n",
      "{}\n",
      "{'loss': 4.0774, 'ndcg_at_40': 0.3463, 'val_loss': 4.8209, 'val_ndcg_at_40': 0.4162}\n",
      "{}\n",
      "{'loss': 4.1946, 'ndcg_at_40': 0.3537, 'val_loss': 4.9139, 'val_ndcg_at_40': 0.3933}\n",
      "{}\n",
      "{'loss': 4.3387, 'ndcg_at_40': 0.3563, 'val_loss': 5.192, 'val_ndcg_at_40': 0.4165}\n",
      "{}\n",
      "{'loss': 4.3983, 'ndcg_at_40': 0.3582, 'val_loss': 4.6551, 'val_ndcg_at_40': 0.4139}\n",
      "{}\n",
      "{'loss': 4.1755, 'ndcg_at_40': 0.3571, 'val_loss': 5.1607, 'val_ndcg_at_40': 0.4157}\n",
      "{}\n",
      "{'loss': 4.5479, 'ndcg_at_40': 0.3672, 'val_loss': 5.4024, 'val_ndcg_at_40': 0.4173}\n",
      "{}\n",
      "{'loss': 4.6823, 'ndcg_at_40': 0.3609, 'val_loss': 5.3548, 'val_ndcg_at_40': 0.414}\n",
      "{}\n",
      "{'loss': 4.6699, 'ndcg_at_40': 0.3633, 'val_loss': 5.6065, 'val_ndcg_at_40': 0.4144}\n",
      "{}\n",
      "{'loss': 4.6789, 'ndcg_at_40': 0.3497, 'val_loss': 5.3374, 'val_ndcg_at_40': 0.4091}\n",
      "{}\n",
      "{'loss': 4.7973, 'ndcg_at_40': 0.3463, 'val_loss': 5.5553, 'val_ndcg_at_40': 0.4161}\n",
      "{}\n",
      "{'loss': 4.9032, 'ndcg_at_40': 0.3552, 'val_loss': 5.771, 'val_ndcg_at_40': 0.4173}\n",
      "{}\n",
      "{'loss': 5.1711, 'ndcg_at_40': 0.3502, 'val_loss': 5.5957, 'val_ndcg_at_40': 0.4126}\n",
      "{}\n",
      "{'loss': 4.9827, 'ndcg_at_40': 0.3529, 'val_loss': 6.1107, 'val_ndcg_at_40': 0.4159}\n",
      "{}\n",
      "{'loss': 5.3148, 'ndcg_at_40': 0.358, 'val_loss': 6.2478, 'val_ndcg_at_40': 0.4042}\n",
      "{}\n",
      "{'loss': 5.3776, 'ndcg_at_40': 0.3614, 'val_loss': 6.0769, 'val_ndcg_at_40': 0.4169}\n",
      "{}\n",
      "{'loss': 5.4506, 'ndcg_at_40': 0.3705, 'val_loss': 6.2519, 'val_ndcg_at_40': 0.4163}\n",
      "{}\n",
      "{'loss': 5.5694, 'ndcg_at_40': 0.3617, 'val_loss': 6.3736, 'val_ndcg_at_40': 0.4151}\n",
      "{}\n",
      "{'loss': 5.7281, 'ndcg_at_40': 0.3634, 'val_loss': 6.3175, 'val_ndcg_at_40': 0.4067}\n",
      "{}\n",
      "{'loss': 5.6746, 'ndcg_at_40': 0.3642, 'val_loss': 6.1663, 'val_ndcg_at_40': 0.4088}\n",
      "{}\n",
      "{'loss': 5.5888, 'ndcg_at_40': 0.3608, 'val_loss': 6.2809, 'val_ndcg_at_40': 0.41}\n",
      "{}\n",
      "{'loss': 5.7597, 'ndcg_at_40': 0.3699, 'val_loss': 6.6745, 'val_ndcg_at_40': 0.4142}\n",
      "{}\n",
      "{'loss': 5.9277, 'ndcg_at_40': 0.3681, 'val_loss': 6.696, 'val_ndcg_at_40': 0.4139}\n",
      "{}\n",
      "{'loss': 5.9659, 'ndcg_at_40': 0.3645, 'val_loss': 6.8739, 'val_ndcg_at_40': 0.4146}\n",
      "{}\n",
      "{'loss': 6.1679, 'ndcg_at_40': 0.3787, 'val_loss': 6.9331, 'val_ndcg_at_40': 0.4184}\n",
      "{}\n",
      "{'loss': 6.3232, 'ndcg_at_40': 0.3741, 'val_loss': 6.9525, 'val_ndcg_at_40': 0.4143}\n",
      "{}\n",
      "{'loss': 6.2418, 'ndcg_at_40': 0.3757, 'val_loss': 7.1777, 'val_ndcg_at_40': 0.4168}\n",
      "{}\n",
      "{'loss': 6.4211, 'ndcg_at_40': 0.3718, 'val_loss': 7.417, 'val_ndcg_at_40': 0.418}\n",
      "{}\n",
      "{'loss': 6.8001, 'ndcg_at_40': 0.3718, 'val_loss': 7.5194, 'val_ndcg_at_40': 0.4156}\n",
      "{}\n",
      "{'loss': 6.8146, 'ndcg_at_40': 0.378, 'val_loss': 7.6798, 'val_ndcg_at_40': 0.4162}\n",
      "{}\n",
      "{'loss': 6.9431, 'ndcg_at_40': 0.3773, 'val_loss': 7.5625, 'val_ndcg_at_40': 0.4178}\n",
      "{}\n",
      "{'loss': 6.8509, 'ndcg_at_40': 0.3761, 'val_loss': 7.8855, 'val_ndcg_at_40': 0.4145}\n",
      "{}\n",
      "{'loss': 7.0981, 'ndcg_at_40': 0.3703, 'val_loss': 7.9927, 'val_ndcg_at_40': 0.4118}\n",
      "{}\n",
      "{'loss': 7.175, 'ndcg_at_40': 0.3579, 'val_loss': 8.1715, 'val_ndcg_at_40': 0.4092}\n",
      "{}\n",
      "{'loss': 7.2208, 'ndcg_at_40': 0.3543, 'val_loss': 8.2489, 'val_ndcg_at_40': 0.4117}\n",
      "{}\n",
      "{'loss': 7.3576, 'ndcg_at_40': 0.3691, 'val_loss': 8.2549, 'val_ndcg_at_40': 0.4099}\n",
      "{}\n",
      "{'loss': 7.5658, 'ndcg_at_40': 0.3731, 'val_loss': 8.2585, 'val_ndcg_at_40': 0.4085}\n",
      "{}\n",
      "{'loss': 7.4692, 'ndcg_at_40': 0.3731, 'val_loss': 8.5485, 'val_ndcg_at_40': 0.4034}\n",
      "{}\n",
      "{'loss': 7.6959, 'ndcg_at_40': 0.3612, 'val_loss': 8.5472, 'val_ndcg_at_40': 0.4172}\n",
      "{}\n",
      "{'loss': 7.7553, 'ndcg_at_40': 0.3745, 'val_loss': 8.6624, 'val_ndcg_at_40': 0.4062}\n",
      "{}\n",
      "{'loss': 7.918, 'ndcg_at_40': 0.3797, 'val_loss': 8.5803, 'val_ndcg_at_40': 0.4021}\n",
      "{}\n",
      "{'loss': 7.7327, 'ndcg_at_40': 0.3761, 'val_loss': 8.8434, 'val_ndcg_at_40': 0.4063}\n",
      "{}\n",
      "{'loss': 8.1397, 'ndcg_at_40': 0.3711, 'val_loss': 8.8789, 'val_ndcg_at_40': 0.4037}\n",
      "{}\n",
      "{'loss': 8.0975, 'ndcg_at_40': 0.3845, 'val_loss': 8.6396, 'val_ndcg_at_40': 0.3984}\n",
      "{}\n",
      "{'loss': 8.008, 'ndcg_at_40': 0.3785, 'val_loss': 8.9605, 'val_ndcg_at_40': 0.404}\n",
      "{}\n",
      "{'loss': 8.3218, 'ndcg_at_40': 0.3867, 'val_loss': 8.9611, 'val_ndcg_at_40': 0.4008}\n",
      "{}\n",
      "{'loss': 8.3012, 'ndcg_at_40': 0.3808, 'val_loss': 8.7959, 'val_ndcg_at_40': 0.3929}\n",
      "{}\n",
      "{'loss': 8.217, 'ndcg_at_40': 0.3741, 'val_loss': 9.0505, 'val_ndcg_at_40': 0.4004}\n",
      "{}\n",
      "{'loss': 8.3171, 'ndcg_at_40': 0.3804, 'val_loss': 9.2196, 'val_ndcg_at_40': 0.4093}\n",
      "{}\n",
      "{'loss': 8.5339, 'ndcg_at_40': 0.3814, 'val_loss': 9.1211, 'val_ndcg_at_40': 0.4107}\n",
      "{}\n",
      "{'loss': 8.3243, 'ndcg_at_40': 0.3858, 'val_loss': 9.3975, 'val_ndcg_at_40': 0.4069}\n",
      "{}\n",
      "{'loss': 8.5924, 'ndcg_at_40': 0.3897, 'val_loss': 9.273, 'val_ndcg_at_40': 0.404}\n",
      "{}\n",
      "{'loss': 8.6454, 'ndcg_at_40': 0.3886, 'val_loss': 9.4439, 'val_ndcg_at_40': 0.4039}\n",
      "{}\n",
      "{'loss': 8.6728, 'ndcg_at_40': 0.3891, 'val_loss': 9.4059, 'val_ndcg_at_40': 0.396}\n",
      "{}\n",
      "{'loss': 8.629, 'ndcg_at_40': 0.3885, 'val_loss': 9.6046, 'val_ndcg_at_40': 0.4013}\n",
      "{}\n",
      "{'loss': 8.8791, 'ndcg_at_40': 0.3911, 'val_loss': 9.7495, 'val_ndcg_at_40': 0.4074}\n",
      "{}\n",
      "{'loss': 8.9841, 'ndcg_at_40': 0.3864, 'val_loss': 9.5327, 'val_ndcg_at_40': 0.4092}\n",
      "{}\n",
      "{'loss': 8.8173, 'ndcg_at_40': 0.3858, 'val_loss': 9.8575, 'val_ndcg_at_40': 0.41}\n",
      "{}\n",
      "{'loss': 9.1521, 'ndcg_at_40': 0.3873, 'val_loss': 9.9683, 'val_ndcg_at_40': 0.4102}\n",
      "{}\n",
      "{'loss': 9.1844, 'ndcg_at_40': 0.3897, 'val_loss': 10.0307, 'val_ndcg_at_40': 0.4097}\n",
      "{}\n",
      "{'loss': 9.2146, 'ndcg_at_40': 0.3994, 'val_loss': 10.2523, 'val_ndcg_at_40': 0.408}\n",
      "{}\n",
      "{'loss': 9.4433, 'ndcg_at_40': 0.3914, 'val_loss': 10.0214, 'val_ndcg_at_40': 0.4059}\n",
      "{}\n",
      "{'loss': 9.442, 'ndcg_at_40': 0.3927, 'val_loss': 10.0355, 'val_ndcg_at_40': 0.4083}\n",
      "{}\n",
      "{'loss': 9.3851, 'ndcg_at_40': 0.3926, 'val_loss': 10.1278, 'val_ndcg_at_40': 0.4116}\n",
      "{}\n",
      "{'loss': 9.4377, 'ndcg_at_40': 0.3943, 'val_loss': 10.2364, 'val_ndcg_at_40': 0.4045}\n",
      "{}\n",
      "{'loss': 0.9074, 'ndcg_at_40': 0.0247, 'val_loss': 0.5115, 'val_ndcg_at_40': 0.0357}\n",
      "{}\n",
      "{'loss': 0.4417, 'ndcg_at_40': 0.0229, 'val_loss': 0.1297, 'val_ndcg_at_40': 0.0331}\n",
      "{}\n",
      "{'loss': 0.11, 'ndcg_at_40': 0.0254, 'val_loss': 0.0422, 'val_ndcg_at_40': 0.0337}\n",
      "{}\n",
      "{'loss': 0.0565, 'ndcg_at_40': 0.0246, 'val_loss': 0.0933, 'val_ndcg_at_40': 0.0311}\n",
      "{}\n",
      "{'loss': 0.0969, 'ndcg_at_40': 0.0237, 'val_loss': 0.1215, 'val_ndcg_at_40': 0.0442}\n",
      "{}\n",
      "{'loss': 0.1289, 'ndcg_at_40': 0.0231, 'val_loss': 0.1544, 'val_ndcg_at_40': 0.0466}\n",
      "{}\n",
      "{'loss': 0.1586, 'ndcg_at_40': 0.0245, 'val_loss': 0.179, 'val_ndcg_at_40': 0.0565}\n",
      "{}\n",
      "{'loss': 0.1856, 'ndcg_at_40': 0.0221, 'val_loss': 0.2144, 'val_ndcg_at_40': 0.0449}\n",
      "{}\n",
      "{'loss': 0.2214, 'ndcg_at_40': 0.0237, 'val_loss': 0.2419, 'val_ndcg_at_40': 0.0355}\n",
      "{}\n",
      "{'loss': 0.2496, 'ndcg_at_40': 0.0242, 'val_loss': 0.2716, 'val_ndcg_at_40': 0.0425}\n",
      "{}\n",
      "{'loss': 0.2786, 'ndcg_at_40': 0.0237, 'val_loss': 0.3014, 'val_ndcg_at_40': 0.0458}\n",
      "{}\n",
      "{'loss': 0.3073, 'ndcg_at_40': 0.0249, 'val_loss': 0.3292, 'val_ndcg_at_40': 0.0471}\n",
      "{}\n",
      "{'loss': 0.3364, 'ndcg_at_40': 0.0225, 'val_loss': 0.3531, 'val_ndcg_at_40': 0.0257}\n",
      "{}\n",
      "{'loss': 0.3582, 'ndcg_at_40': 0.0232, 'val_loss': 0.377, 'val_ndcg_at_40': 0.0601}\n",
      "{}\n",
      "{'loss': 0.3834, 'ndcg_at_40': 0.0208, 'val_loss': 0.4024, 'val_ndcg_at_40': 0.0387}\n",
      "{}\n",
      "{'loss': 0.4092, 'ndcg_at_40': 0.0222, 'val_loss': 0.4308, 'val_ndcg_at_40': 0.0269}\n",
      "{}\n",
      "{'loss': 0.4363, 'ndcg_at_40': 0.0225, 'val_loss': 0.4501, 'val_ndcg_at_40': 0.0313}\n",
      "{}\n",
      "{'loss': 0.4541, 'ndcg_at_40': 0.0227, 'val_loss': 0.4659, 'val_ndcg_at_40': 0.036}\n",
      "{}\n",
      "{'loss': 0.4704, 'ndcg_at_40': 0.0251, 'val_loss': 0.4783, 'val_ndcg_at_40': 0.0369}\n",
      "{}\n",
      "{'loss': 0.4838, 'ndcg_at_40': 0.0203, 'val_loss': 0.5055, 'val_ndcg_at_40': 0.0517}\n",
      "{}\n",
      "{'loss': 0.513, 'ndcg_at_40': 0.0211, 'val_loss': 0.5343, 'val_ndcg_at_40': 0.0382}\n",
      "{}\n",
      "{'loss': 0.5397, 'ndcg_at_40': 0.021, 'val_loss': 0.5564, 'val_ndcg_at_40': 0.039}\n",
      "{}\n",
      "{'loss': 0.5632, 'ndcg_at_40': 0.0242, 'val_loss': 0.5849, 'val_ndcg_at_40': 0.0481}\n",
      "{}\n",
      "{'loss': 0.5904, 'ndcg_at_40': 0.0246, 'val_loss': 0.6082, 'val_ndcg_at_40': 0.029}\n",
      "{}\n",
      "{'loss': 0.6138, 'ndcg_at_40': 0.024, 'val_loss': 0.6291, 'val_ndcg_at_40': 0.0393}\n",
      "{}\n",
      "{'loss': 0.6354, 'ndcg_at_40': 0.0217, 'val_loss': 0.6555, 'val_ndcg_at_40': 0.066}\n",
      "{}\n",
      "{'loss': 0.6596, 'ndcg_at_40': 0.0237, 'val_loss': 0.6736, 'val_ndcg_at_40': 0.0574}\n",
      "{}\n",
      "{'loss': 0.6773, 'ndcg_at_40': 0.0245, 'val_loss': 0.6907, 'val_ndcg_at_40': 0.0732}\n",
      "{}\n",
      "{'loss': 0.6971, 'ndcg_at_40': 0.0218, 'val_loss': 0.7146, 'val_ndcg_at_40': 0.0745}\n",
      "{}\n",
      "{'loss': 0.7216, 'ndcg_at_40': 0.0222, 'val_loss': 0.7425, 'val_ndcg_at_40': 0.0513}\n",
      "{}\n",
      "{'loss': 0.7485, 'ndcg_at_40': 0.0246, 'val_loss': 0.7717, 'val_ndcg_at_40': 0.047}\n",
      "{}\n",
      "{'loss': 0.7799, 'ndcg_at_40': 0.0224, 'val_loss': 0.7992, 'val_ndcg_at_40': 0.0752}\n",
      "{}\n",
      "{'loss': 0.804, 'ndcg_at_40': 0.0254, 'val_loss': 0.8185, 'val_ndcg_at_40': 0.0808}\n",
      "{}\n",
      "{'loss': 0.8234, 'ndcg_at_40': 0.0255, 'val_loss': 0.8386, 'val_ndcg_at_40': 0.1169}\n",
      "{}\n",
      "{'loss': 0.8447, 'ndcg_at_40': 0.0256, 'val_loss': 0.8577, 'val_ndcg_at_40': 0.0691}\n",
      "{}\n",
      "{'loss': 0.8621, 'ndcg_at_40': 0.0265, 'val_loss': 0.8803, 'val_ndcg_at_40': 0.0964}\n",
      "{}\n",
      "{'loss': 0.887, 'ndcg_at_40': 0.0283, 'val_loss': 0.9077, 'val_ndcg_at_40': 0.1025}\n",
      "{}\n",
      "{'loss': 0.915, 'ndcg_at_40': 0.0288, 'val_loss': 0.9354, 'val_ndcg_at_40': 0.1012}\n",
      "{}\n",
      "{'loss': 0.9405, 'ndcg_at_40': 0.0256, 'val_loss': 0.9566, 'val_ndcg_at_40': 0.076}\n",
      "{}\n",
      "{'loss': 0.9643, 'ndcg_at_40': 0.0267, 'val_loss': 0.9868, 'val_ndcg_at_40': 0.0893}\n",
      "{}\n",
      "{'loss': 0.9929, 'ndcg_at_40': 0.0277, 'val_loss': 1.0152, 'val_ndcg_at_40': 0.1299}\n",
      "{}\n",
      "{'loss': 1.0216, 'ndcg_at_40': 0.0306, 'val_loss': 1.0464, 'val_ndcg_at_40': 0.1168}\n",
      "{}\n",
      "{'loss': 1.0533, 'ndcg_at_40': 0.0284, 'val_loss': 1.0691, 'val_ndcg_at_40': 0.0981}\n",
      "{}\n",
      "{'loss': 1.0747, 'ndcg_at_40': 0.0302, 'val_loss': 1.0942, 'val_ndcg_at_40': 0.1058}\n",
      "{}\n",
      "{'loss': 1.0994, 'ndcg_at_40': 0.0303, 'val_loss': 1.115, 'val_ndcg_at_40': 0.1094}\n",
      "{}\n",
      "{'loss': 1.1226, 'ndcg_at_40': 0.0344, 'val_loss': 1.1506, 'val_ndcg_at_40': 0.0966}\n",
      "{}\n",
      "{'loss': 1.1594, 'ndcg_at_40': 0.0309, 'val_loss': 1.1855, 'val_ndcg_at_40': 0.123}\n",
      "{}\n",
      "{'loss': 1.1935, 'ndcg_at_40': 0.0324, 'val_loss': 1.2187, 'val_ndcg_at_40': 0.1121}\n",
      "{}\n",
      "{'loss': 1.2233, 'ndcg_at_40': 0.036, 'val_loss': 1.2383, 'val_ndcg_at_40': 0.1063}\n",
      "{}\n",
      "{'loss': 1.2453, 'ndcg_at_40': 0.0347, 'val_loss': 1.2669, 'val_ndcg_at_40': 0.1199}\n",
      "{}\n",
      "{'loss': 1.2768, 'ndcg_at_40': 0.0373, 'val_loss': 1.2999, 'val_ndcg_at_40': 0.1282}\n",
      "{}\n",
      "{'loss': 1.306, 'ndcg_at_40': 0.0394, 'val_loss': 1.3235, 'val_ndcg_at_40': 0.1165}\n",
      "{}\n",
      "{'loss': 1.3287, 'ndcg_at_40': 0.0384, 'val_loss': 1.3481, 'val_ndcg_at_40': 0.1356}\n",
      "{}\n",
      "{'loss': 1.3555, 'ndcg_at_40': 0.0429, 'val_loss': 1.3712, 'val_ndcg_at_40': 0.1333}\n",
      "{}\n",
      "{'loss': 1.3747, 'ndcg_at_40': 0.0468, 'val_loss': 1.3895, 'val_ndcg_at_40': 0.1445}\n",
      "{}\n",
      "{'loss': 1.3969, 'ndcg_at_40': 0.0454, 'val_loss': 1.4196, 'val_ndcg_at_40': 0.1145}\n",
      "{}\n",
      "{'loss': 1.4264, 'ndcg_at_40': 0.0444, 'val_loss': 1.4417, 'val_ndcg_at_40': 0.1162}\n",
      "{}\n",
      "{'loss': 1.4467, 'ndcg_at_40': 0.0464, 'val_loss': 1.4603, 'val_ndcg_at_40': 0.124}\n",
      "{}\n",
      "{'loss': 1.4652, 'ndcg_at_40': 0.0469, 'val_loss': 1.4838, 'val_ndcg_at_40': 0.1357}\n",
      "{}\n",
      "{'loss': 1.492, 'ndcg_at_40': 0.0493, 'val_loss': 1.517, 'val_ndcg_at_40': 0.1363}\n",
      "{}\n",
      "{'loss': 1.5208, 'ndcg_at_40': 0.0501, 'val_loss': 1.5298, 'val_ndcg_at_40': 0.1252}\n",
      "{}\n",
      "{'loss': 1.5325, 'ndcg_at_40': 0.0503, 'val_loss': 1.5442, 'val_ndcg_at_40': 0.1337}\n",
      "{}\n",
      "{'loss': 1.5492, 'ndcg_at_40': 0.048, 'val_loss': 1.5634, 'val_ndcg_at_40': 0.156}\n",
      "{}\n",
      "{'loss': 1.565, 'ndcg_at_40': 0.054, 'val_loss': 1.5736, 'val_ndcg_at_40': 0.173}\n",
      "{}\n",
      "{'loss': 1.5767, 'ndcg_at_40': 0.0582, 'val_loss': 1.5871, 'val_ndcg_at_40': 0.1362}\n",
      "{}\n",
      "{'loss': 1.5888, 'ndcg_at_40': 0.054, 'val_loss': 1.5975, 'val_ndcg_at_40': 0.1622}\n",
      "{}\n",
      "{'loss': 1.5992, 'ndcg_at_40': 0.0551, 'val_loss': 1.6082, 'val_ndcg_at_40': 0.1617}\n",
      "{}\n",
      "{'loss': 1.6132, 'ndcg_at_40': 0.0561, 'val_loss': 1.6285, 'val_ndcg_at_40': 0.1561}\n",
      "{}\n",
      "{'loss': 1.6324, 'ndcg_at_40': 0.056, 'val_loss': 1.6419, 'val_ndcg_at_40': 0.1809}\n",
      "{}\n",
      "{'loss': 1.6453, 'ndcg_at_40': 0.0652, 'val_loss': 1.6508, 'val_ndcg_at_40': 0.175}\n",
      "{}\n",
      "{'loss': 1.6563, 'ndcg_at_40': 0.0669, 'val_loss': 1.6679, 'val_ndcg_at_40': 0.1455}\n",
      "{}\n",
      "{'loss': 1.6713, 'ndcg_at_40': 0.0644, 'val_loss': 1.679, 'val_ndcg_at_40': 0.1621}\n",
      "{}\n",
      "{'loss': 1.6828, 'ndcg_at_40': 0.0626, 'val_loss': 1.6955, 'val_ndcg_at_40': 0.1755}\n",
      "{}\n",
      "{'loss': 1.6985, 'ndcg_at_40': 0.0691, 'val_loss': 1.7133, 'val_ndcg_at_40': 0.1938}\n",
      "{}\n",
      "{'loss': 1.7189, 'ndcg_at_40': 0.0697, 'val_loss': 1.7321, 'val_ndcg_at_40': 0.1614}\n",
      "{}\n",
      "{'loss': 1.7382, 'ndcg_at_40': 0.0804, 'val_loss': 1.7587, 'val_ndcg_at_40': 0.1728}\n",
      "{}\n",
      "{'loss': 1.7631, 'ndcg_at_40': 0.0758, 'val_loss': 1.7778, 'val_ndcg_at_40': 0.1519}\n",
      "{}\n",
      "{'loss': 1.7843, 'ndcg_at_40': 0.0791, 'val_loss': 1.8022, 'val_ndcg_at_40': 0.1714}\n",
      "{}\n",
      "{'loss': 1.8043, 'ndcg_at_40': 0.0857, 'val_loss': 1.8131, 'val_ndcg_at_40': 0.191}\n",
      "{}\n",
      "{'loss': 1.8161, 'ndcg_at_40': 0.0745, 'val_loss': 1.8272, 'val_ndcg_at_40': 0.1893}\n",
      "{}\n",
      "{'loss': 1.8293, 'ndcg_at_40': 0.0834, 'val_loss': 1.8342, 'val_ndcg_at_40': 0.1885}\n",
      "{}\n",
      "{'loss': 1.84, 'ndcg_at_40': 0.0831, 'val_loss': 1.8587, 'val_ndcg_at_40': 0.1597}\n",
      "{}\n",
      "{'loss': 1.8657, 'ndcg_at_40': 0.0952, 'val_loss': 1.8799, 'val_ndcg_at_40': 0.2038}\n",
      "{}\n",
      "{'loss': 1.8857, 'ndcg_at_40': 0.0976, 'val_loss': 1.8984, 'val_ndcg_at_40': 0.2025}\n",
      "{}\n",
      "{'loss': 1.9052, 'ndcg_at_40': 0.0941, 'val_loss': 1.9309, 'val_ndcg_at_40': 0.2062}\n",
      "{}\n",
      "{'loss': 1.9391, 'ndcg_at_40': 0.104, 'val_loss': 1.9562, 'val_ndcg_at_40': 0.1838}\n",
      "{}\n",
      "{'loss': 1.9606, 'ndcg_at_40': 0.1003, 'val_loss': 1.9713, 'val_ndcg_at_40': 0.181}\n",
      "{}\n",
      "{'loss': 1.9747, 'ndcg_at_40': 0.1052, 'val_loss': 1.9853, 'val_ndcg_at_40': 0.2395}\n",
      "{}\n",
      "{'loss': 1.9882, 'ndcg_at_40': 0.1066, 'val_loss': 1.9986, 'val_ndcg_at_40': 0.2301}\n",
      "{}\n",
      "{'loss': 2.0037, 'ndcg_at_40': 0.1261, 'val_loss': 2.025, 'val_ndcg_at_40': 0.2805}\n",
      "{}\n",
      "{'loss': 2.0309, 'ndcg_at_40': 0.1372, 'val_loss': 2.044, 'val_ndcg_at_40': 0.2676}\n",
      "{}\n",
      "{'loss': 2.0471, 'ndcg_at_40': 0.1501, 'val_loss': 2.0571, 'val_ndcg_at_40': 0.2545}\n",
      "{}\n",
      "{'loss': 2.0593, 'ndcg_at_40': 0.15, 'val_loss': 2.0739, 'val_ndcg_at_40': 0.2714}\n",
      "{}\n",
      "{'loss': 2.0831, 'ndcg_at_40': 0.1462, 'val_loss': 2.1047, 'val_ndcg_at_40': 0.2742}\n",
      "{}\n",
      "{'loss': 2.1107, 'ndcg_at_40': 0.1455, 'val_loss': 2.122, 'val_ndcg_at_40': 0.2387}\n",
      "{}\n",
      "{'loss': 2.1224, 'ndcg_at_40': 0.1474, 'val_loss': 2.1306, 'val_ndcg_at_40': 0.2618}\n",
      "{}\n",
      "{'loss': 2.1332, 'ndcg_at_40': 0.1631, 'val_loss': 2.1498, 'val_ndcg_at_40': 0.2707}\n",
      "{}\n",
      "{'loss': 2.153, 'ndcg_at_40': 0.1497, 'val_loss': 2.1674, 'val_ndcg_at_40': 0.2802}\n",
      "{}\n",
      "{'loss': 2.1754, 'ndcg_at_40': 0.1599, 'val_loss': 2.1945, 'val_ndcg_at_40': 0.2957}\n",
      "{}\n",
      "{'loss': 2.1973, 'ndcg_at_40': 0.1639, 'val_loss': 2.2129, 'val_ndcg_at_40': 0.2418}\n",
      "{}\n",
      "{'loss': 2.218, 'ndcg_at_40': 0.1595, 'val_loss': 2.2286, 'val_ndcg_at_40': 0.2976}\n",
      "{}\n",
      "{'loss': 2.2322, 'ndcg_at_40': 0.164, 'val_loss': 2.2428, 'val_ndcg_at_40': 0.2818}\n",
      "{}\n",
      "{'loss': 2.2419, 'ndcg_at_40': 0.1551, 'val_loss': 2.2406, 'val_ndcg_at_40': 0.2941}\n",
      "{}\n",
      "{'loss': 2.2431, 'ndcg_at_40': 0.158, 'val_loss': 2.2568, 'val_ndcg_at_40': 0.2772}\n",
      "{}\n",
      "{'loss': 2.2601, 'ndcg_at_40': 0.168, 'val_loss': 2.2673, 'val_ndcg_at_40': 0.2882}\n",
      "{}\n",
      "{'loss': 2.2712, 'ndcg_at_40': 0.1571, 'val_loss': 2.2796, 'val_ndcg_at_40': 0.3029}\n",
      "{}\n",
      "{'loss': 2.2818, 'ndcg_at_40': 0.1543, 'val_loss': 2.2904, 'val_ndcg_at_40': 0.2898}\n",
      "{}\n",
      "{'loss': 2.295, 'ndcg_at_40': 0.1701, 'val_loss': 2.3034, 'val_ndcg_at_40': 0.31}\n",
      "{}\n",
      "{'loss': 2.3035, 'ndcg_at_40': 0.1629, 'val_loss': 2.3019, 'val_ndcg_at_40': 0.2607}\n",
      "{}\n",
      "{'loss': 2.3011, 'ndcg_at_40': 0.1587, 'val_loss': 2.293, 'val_ndcg_at_40': 0.2971}\n",
      "{}\n",
      "{'loss': 2.2925, 'ndcg_at_40': 0.1628, 'val_loss': 2.292, 'val_ndcg_at_40': 0.3112}\n",
      "{}\n",
      "{'loss': 2.292, 'ndcg_at_40': 0.1588, 'val_loss': 2.2905, 'val_ndcg_at_40': 0.2919}\n",
      "{}\n",
      "{'loss': 2.2889, 'ndcg_at_40': 0.1666, 'val_loss': 2.2891, 'val_ndcg_at_40': 0.3034}\n",
      "{}\n",
      "{'loss': 2.2858, 'ndcg_at_40': 0.1612, 'val_loss': 2.2777, 'val_ndcg_at_40': 0.276}\n",
      "{}\n",
      "{'loss': 2.2775, 'ndcg_at_40': 0.1651, 'val_loss': 2.2757, 'val_ndcg_at_40': 0.3089}\n",
      "{}\n",
      "{'loss': 2.2724, 'ndcg_at_40': 0.1686, 'val_loss': 2.2654, 'val_ndcg_at_40': 0.3069}\n",
      "{}\n",
      "{'loss': 2.264, 'ndcg_at_40': 0.1543, 'val_loss': 2.2569, 'val_ndcg_at_40': 0.3048}\n",
      "{}\n",
      "{'loss': 2.2558, 'ndcg_at_40': 0.1576, 'val_loss': 2.2557, 'val_ndcg_at_40': 0.2814}\n",
      "{}\n",
      "{'loss': 2.2519, 'ndcg_at_40': 0.1538, 'val_loss': 2.2398, 'val_ndcg_at_40': 0.2565}\n",
      "{}\n",
      "{'loss': 2.2302, 'ndcg_at_40': 0.1317, 'val_loss': 1.9363, 'val_ndcg_at_40': 0.1081}\n",
      "{}\n",
      "{'loss': 2.0048, 'ndcg_at_40': 0.122, 'val_loss': 1.8839, 'val_ndcg_at_40': 0.0769}\n",
      "{}\n",
      "{'loss': 1.9121, 'ndcg_at_40': 0.1043, 'val_loss': 1.7865, 'val_ndcg_at_40': 0.1088}\n",
      "{}\n",
      "{'loss': 1.9368, 'ndcg_at_40': 0.1013, 'val_loss': 1.7655, 'val_ndcg_at_40': 0.1242}\n",
      "{}\n",
      "{'loss': 1.8577, 'ndcg_at_40': 0.0868, 'val_loss': 1.5308, 'val_ndcg_at_40': 0.1145}\n",
      "{}\n",
      "{'loss': 1.7653, 'ndcg_at_40': 0.0995, 'val_loss': 1.6163, 'val_ndcg_at_40': 0.1315}\n",
      "{}\n",
      "{'loss': 1.7779, 'ndcg_at_40': 0.101, 'val_loss': 1.6515, 'val_ndcg_at_40': 0.1074}\n",
      "{}\n",
      "{'loss': 1.7296, 'ndcg_at_40': 0.1044, 'val_loss': 1.68, 'val_ndcg_at_40': 0.1201}\n",
      "{}\n",
      "{'loss': 1.7314, 'ndcg_at_40': 0.102, 'val_loss': 1.662, 'val_ndcg_at_40': 0.1729}\n",
      "{}\n",
      "{'loss': 1.7239, 'ndcg_at_40': 0.1165, 'val_loss': 1.6636, 'val_ndcg_at_40': 0.1047}\n",
      "{}\n",
      "{'loss': 1.6843, 'ndcg_at_40': 0.1235, 'val_loss': 1.7604, 'val_ndcg_at_40': 0.0475}\n",
      "{}\n",
      "{'loss': 1.7528, 'ndcg_at_40': 0.1256, 'val_loss': 1.7118, 'val_ndcg_at_40': 0.0967}\n",
      "{}\n",
      "{'loss': 1.6683, 'ndcg_at_40': 0.1397, 'val_loss': 1.7782, 'val_ndcg_at_40': 0.0765}\n",
      "{}\n",
      "{'loss': 1.7323, 'ndcg_at_40': 0.1472, 'val_loss': 1.8223, 'val_ndcg_at_40': 0.0936}\n",
      "{}\n",
      "{'loss': 1.7362, 'ndcg_at_40': 0.15, 'val_loss': 1.8075, 'val_ndcg_at_40': 0.0889}\n",
      "{}\n",
      "{'loss': 1.7525, 'ndcg_at_40': 0.1545, 'val_loss': 1.8919, 'val_ndcg_at_40': 0.0733}\n",
      "{}\n",
      "{'loss': 1.734, 'ndcg_at_40': 0.1499, 'val_loss': 1.9084, 'val_ndcg_at_40': 0.2403}\n",
      "{}\n",
      "{'loss': 1.7957, 'ndcg_at_40': 0.1346, 'val_loss': 1.9017, 'val_ndcg_at_40': 0.0646}\n",
      "{}\n",
      "{'loss': 1.7864, 'ndcg_at_40': 0.1533, 'val_loss': 2.0094, 'val_ndcg_at_40': 0.0834}\n",
      "{}\n",
      "{'loss': 1.889, 'ndcg_at_40': 0.1659, 'val_loss': 1.9626, 'val_ndcg_at_40': 0.1025}\n",
      "{}\n",
      "{'loss': 1.8003, 'ndcg_at_40': 0.1743, 'val_loss': 2.092, 'val_ndcg_at_40': 0.1118}\n",
      "{}\n",
      "{'loss': 1.8976, 'ndcg_at_40': 0.1938, 'val_loss': 2.0261, 'val_ndcg_at_40': 0.099}\n",
      "{}\n",
      "{'loss': 1.8122, 'ndcg_at_40': 0.1699, 'val_loss': 1.9521, 'val_ndcg_at_40': 0.3411}\n",
      "{}\n",
      "{'loss': 1.7956, 'ndcg_at_40': 0.1892, 'val_loss': 2.0764, 'val_ndcg_at_40': 0.2103}\n",
      "{}\n",
      "{'loss': 1.8209, 'ndcg_at_40': 0.2203, 'val_loss': 2.2799, 'val_ndcg_at_40': 0.1692}\n",
      "{}\n",
      "{'loss': 1.8704, 'ndcg_at_40': 0.25, 'val_loss': 2.1087, 'val_ndcg_at_40': 0.1759}\n",
      "{}\n",
      "{'loss': 1.7527, 'ndcg_at_40': 0.2074, 'val_loss': 2.263, 'val_ndcg_at_40': 0.3998}\n",
      "{}\n",
      "{'loss': 1.9633, 'ndcg_at_40': 0.266, 'val_loss': 2.0224, 'val_ndcg_at_40': 0.157}\n",
      "{}\n",
      "{'loss': 1.8757, 'ndcg_at_40': 0.2332, 'val_loss': 2.315, 'val_ndcg_at_40': 0.235}\n",
      "{}\n",
      "{'loss': 1.8446, 'ndcg_at_40': 0.2616, 'val_loss': 2.3838, 'val_ndcg_at_40': 0.3836}\n",
      "{}\n",
      "{'loss': 2.0401, 'ndcg_at_40': 0.2997, 'val_loss': 2.2002, 'val_ndcg_at_40': 0.3471}\n",
      "{}\n",
      "{'loss': 2.0094, 'ndcg_at_40': 0.2967, 'val_loss': 2.2802, 'val_ndcg_at_40': 0.2389}\n",
      "{}\n",
      "{'loss': 1.9383, 'ndcg_at_40': 0.282, 'val_loss': 2.6392, 'val_ndcg_at_40': 0.2408}\n",
      "{}\n",
      "{'loss': 2.1578, 'ndcg_at_40': 0.301, 'val_loss': 2.4052, 'val_ndcg_at_40': 0.2375}\n",
      "{}\n",
      "{'loss': 1.9939, 'ndcg_at_40': 0.2973, 'val_loss': 2.573, 'val_ndcg_at_40': 0.4017}\n",
      "{}\n",
      "{'loss': 2.3417, 'ndcg_at_40': 0.3113, 'val_loss': 2.9809, 'val_ndcg_at_40': 0.4074}\n",
      "{}\n",
      "{'loss': 2.335, 'ndcg_at_40': 0.3126, 'val_loss': 2.9364, 'val_ndcg_at_40': 0.239}\n",
      "{}\n",
      "{'loss': 2.2607, 'ndcg_at_40': 0.3124, 'val_loss': 2.833, 'val_ndcg_at_40': 0.3931}\n",
      "{}\n",
      "{'loss': 2.3632, 'ndcg_at_40': 0.2999, 'val_loss': 2.9265, 'val_ndcg_at_40': 0.409}\n",
      "{}\n",
      "{'loss': 2.468, 'ndcg_at_40': 0.3153, 'val_loss': 3.166, 'val_ndcg_at_40': 0.4058}\n",
      "{}\n",
      "{'loss': 2.6362, 'ndcg_at_40': 0.3144, 'val_loss': 2.8036, 'val_ndcg_at_40': 0.3901}\n",
      "{}\n",
      "{'loss': 2.5603, 'ndcg_at_40': 0.3121, 'val_loss': 3.0473, 'val_ndcg_at_40': 0.3822}\n",
      "{}\n",
      "{'loss': 2.6398, 'ndcg_at_40': 0.3113, 'val_loss': 3.0393, 'val_ndcg_at_40': 0.3892}\n",
      "{}\n",
      "{'loss': 2.5612, 'ndcg_at_40': 0.3198, 'val_loss': 3.2668, 'val_ndcg_at_40': 0.4012}\n",
      "{}\n",
      "{'loss': 2.8173, 'ndcg_at_40': 0.3247, 'val_loss': 3.3712, 'val_ndcg_at_40': 0.3471}\n",
      "{}\n",
      "{'loss': 2.9052, 'ndcg_at_40': 0.3302, 'val_loss': 3.5106, 'val_ndcg_at_40': 0.4158}\n",
      "{}\n",
      "{'loss': 3.0706, 'ndcg_at_40': 0.3427, 'val_loss': 3.2907, 'val_ndcg_at_40': 0.2768}\n",
      "{}\n",
      "{'loss': 2.9426, 'ndcg_at_40': 0.3411, 'val_loss': 3.6755, 'val_ndcg_at_40': 0.4047}\n",
      "{}\n",
      "{'loss': 3.1512, 'ndcg_at_40': 0.349, 'val_loss': 3.6499, 'val_ndcg_at_40': 0.3002}\n",
      "{}\n",
      "{'loss': 3.1344, 'ndcg_at_40': 0.3412, 'val_loss': 3.7462, 'val_ndcg_at_40': 0.2832}\n",
      "{}\n",
      "{'loss': 3.2657, 'ndcg_at_40': 0.3453, 'val_loss': 3.8416, 'val_ndcg_at_40': 0.2605}\n",
      "{}\n",
      "{'loss': 3.2732, 'ndcg_at_40': 0.3252, 'val_loss': 4.008, 'val_ndcg_at_40': 0.3669}\n",
      "{}\n",
      "{'loss': 3.4154, 'ndcg_at_40': 0.3422, 'val_loss': 4.1624, 'val_ndcg_at_40': 0.3963}\n",
      "{}\n",
      "{'loss': 3.5485, 'ndcg_at_40': 0.3523, 'val_loss': 4.2532, 'val_ndcg_at_40': 0.3312}\n",
      "{}\n",
      "{'loss': 3.5349, 'ndcg_at_40': 0.3335, 'val_loss': 4.2895, 'val_ndcg_at_40': 0.2854}\n",
      "{}\n",
      "{'loss': 3.5134, 'ndcg_at_40': 0.3203, 'val_loss': 4.3461, 'val_ndcg_at_40': 0.3199}\n",
      "{}\n",
      "{'loss': 3.6754, 'ndcg_at_40': 0.3353, 'val_loss': 4.0456, 'val_ndcg_at_40': 0.3555}\n",
      "{}\n",
      "{'loss': 3.5222, 'ndcg_at_40': 0.3473, 'val_loss': 4.3579, 'val_ndcg_at_40': 0.4119}\n",
      "{}\n",
      "{'loss': 3.8261, 'ndcg_at_40': 0.3546, 'val_loss': 4.4688, 'val_ndcg_at_40': 0.3741}\n",
      "{}\n",
      "{'loss': 3.8008, 'ndcg_at_40': 0.3515, 'val_loss': 4.7351, 'val_ndcg_at_40': 0.4179}\n",
      "{}\n",
      "{'loss': 3.9613, 'ndcg_at_40': 0.3539, 'val_loss': 4.4943, 'val_ndcg_at_40': 0.4069}\n",
      "{}\n",
      "{'loss': 3.9111, 'ndcg_at_40': 0.3415, 'val_loss': 4.4796, 'val_ndcg_at_40': 0.3986}\n",
      "{}\n",
      "{'loss': 3.8256, 'ndcg_at_40': 0.3259, 'val_loss': 4.5453, 'val_ndcg_at_40': 0.4152}\n",
      "{}\n",
      "{'loss': 3.9163, 'ndcg_at_40': 0.3488, 'val_loss': 4.6622, 'val_ndcg_at_40': 0.416}\n",
      "{}\n",
      "{'loss': 3.8188, 'ndcg_at_40': 0.3405, 'val_loss': 4.6985, 'val_ndcg_at_40': 0.4166}\n",
      "{}\n",
      "{'loss': 4.0774, 'ndcg_at_40': 0.3463, 'val_loss': 4.8209, 'val_ndcg_at_40': 0.4162}\n",
      "{}\n",
      "{'loss': 4.1946, 'ndcg_at_40': 0.3537, 'val_loss': 4.9139, 'val_ndcg_at_40': 0.3933}\n",
      "{}\n",
      "{'loss': 4.3387, 'ndcg_at_40': 0.3563, 'val_loss': 5.192, 'val_ndcg_at_40': 0.4165}\n",
      "{}\n",
      "{'loss': 4.3983, 'ndcg_at_40': 0.3582, 'val_loss': 4.6551, 'val_ndcg_at_40': 0.4139}\n",
      "{}\n",
      "{'loss': 4.1755, 'ndcg_at_40': 0.3571, 'val_loss': 5.1607, 'val_ndcg_at_40': 0.4157}\n",
      "{}\n",
      "{'loss': 4.5479, 'ndcg_at_40': 0.3672, 'val_loss': 5.4024, 'val_ndcg_at_40': 0.4173}\n",
      "{}\n",
      "{'loss': 4.6823, 'ndcg_at_40': 0.3609, 'val_loss': 5.3548, 'val_ndcg_at_40': 0.414}\n",
      "{}\n",
      "{'loss': 4.6699, 'ndcg_at_40': 0.3633, 'val_loss': 5.6065, 'val_ndcg_at_40': 0.4144}\n",
      "{}\n",
      "{'loss': 4.6789, 'ndcg_at_40': 0.3497, 'val_loss': 5.3374, 'val_ndcg_at_40': 0.4091}\n",
      "{}\n",
      "{'loss': 4.7973, 'ndcg_at_40': 0.3463, 'val_loss': 5.5553, 'val_ndcg_at_40': 0.4161}\n",
      "{}\n",
      "{'loss': 4.9032, 'ndcg_at_40': 0.3552, 'val_loss': 5.771, 'val_ndcg_at_40': 0.4173}\n",
      "{}\n",
      "{'loss': 5.1711, 'ndcg_at_40': 0.3502, 'val_loss': 5.5957, 'val_ndcg_at_40': 0.4126}\n",
      "{}\n",
      "{'loss': 4.9827, 'ndcg_at_40': 0.3529, 'val_loss': 6.1107, 'val_ndcg_at_40': 0.4159}\n",
      "{}\n",
      "{'loss': 5.3148, 'ndcg_at_40': 0.358, 'val_loss': 6.2478, 'val_ndcg_at_40': 0.4042}\n",
      "{}\n",
      "{'loss': 5.3776, 'ndcg_at_40': 0.3614, 'val_loss': 6.0769, 'val_ndcg_at_40': 0.4169}\n",
      "{}\n",
      "{'loss': 5.4506, 'ndcg_at_40': 0.3705, 'val_loss': 6.2519, 'val_ndcg_at_40': 0.4163}\n",
      "{}\n",
      "{'loss': 5.5694, 'ndcg_at_40': 0.3617, 'val_loss': 6.3736, 'val_ndcg_at_40': 0.4151}\n",
      "{}\n",
      "{'loss': 5.7281, 'ndcg_at_40': 0.3634, 'val_loss': 6.3175, 'val_ndcg_at_40': 0.4067}\n",
      "{}\n",
      "{'loss': 5.6746, 'ndcg_at_40': 0.3642, 'val_loss': 6.1663, 'val_ndcg_at_40': 0.4088}\n",
      "{}\n",
      "{'loss': 5.5888, 'ndcg_at_40': 0.3608, 'val_loss': 6.2809, 'val_ndcg_at_40': 0.41}\n",
      "{}\n",
      "{'loss': 5.7597, 'ndcg_at_40': 0.3699, 'val_loss': 6.6745, 'val_ndcg_at_40': 0.4142}\n",
      "{}\n",
      "{'loss': 5.9277, 'ndcg_at_40': 0.3681, 'val_loss': 6.696, 'val_ndcg_at_40': 0.4139}\n",
      "{}\n",
      "{'loss': 5.9659, 'ndcg_at_40': 0.3645, 'val_loss': 6.8739, 'val_ndcg_at_40': 0.4146}\n",
      "{}\n",
      "{'loss': 6.1679, 'ndcg_at_40': 0.3787, 'val_loss': 6.9331, 'val_ndcg_at_40': 0.4184}\n",
      "{}\n",
      "{'loss': 6.3232, 'ndcg_at_40': 0.3741, 'val_loss': 6.9525, 'val_ndcg_at_40': 0.4143}\n",
      "{}\n",
      "{'loss': 6.2418, 'ndcg_at_40': 0.3757, 'val_loss': 7.1777, 'val_ndcg_at_40': 0.4168}\n",
      "{}\n",
      "{'loss': 6.4211, 'ndcg_at_40': 0.3718, 'val_loss': 7.417, 'val_ndcg_at_40': 0.418}\n",
      "{}\n",
      "{'loss': 6.8001, 'ndcg_at_40': 0.3718, 'val_loss': 7.5194, 'val_ndcg_at_40': 0.4156}\n",
      "{}\n",
      "{'loss': 6.8146, 'ndcg_at_40': 0.378, 'val_loss': 7.6798, 'val_ndcg_at_40': 0.4162}\n",
      "{}\n",
      "{'loss': 6.9431, 'ndcg_at_40': 0.3773, 'val_loss': 7.5625, 'val_ndcg_at_40': 0.4178}\n",
      "{}\n",
      "{'loss': 6.8509, 'ndcg_at_40': 0.3761, 'val_loss': 7.8855, 'val_ndcg_at_40': 0.4145}\n",
      "{}\n",
      "{'loss': 7.0981, 'ndcg_at_40': 0.3703, 'val_loss': 7.9927, 'val_ndcg_at_40': 0.4118}\n",
      "{}\n",
      "{'loss': 7.175, 'ndcg_at_40': 0.3579, 'val_loss': 8.1715, 'val_ndcg_at_40': 0.4092}\n",
      "{}\n",
      "{'loss': 7.2208, 'ndcg_at_40': 0.3543, 'val_loss': 8.2489, 'val_ndcg_at_40': 0.4117}\n",
      "{}\n",
      "{'loss': 7.3576, 'ndcg_at_40': 0.3691, 'val_loss': 8.2549, 'val_ndcg_at_40': 0.4099}\n",
      "{}\n",
      "{'loss': 7.5658, 'ndcg_at_40': 0.3731, 'val_loss': 8.2585, 'val_ndcg_at_40': 0.4085}\n",
      "{}\n",
      "{'loss': 7.4692, 'ndcg_at_40': 0.3731, 'val_loss': 8.5485, 'val_ndcg_at_40': 0.4034}\n",
      "{}\n",
      "{'loss': 7.6959, 'ndcg_at_40': 0.3612, 'val_loss': 8.5472, 'val_ndcg_at_40': 0.4172}\n",
      "{}\n",
      "{'loss': 7.7553, 'ndcg_at_40': 0.3745, 'val_loss': 8.6624, 'val_ndcg_at_40': 0.4062}\n",
      "{}\n",
      "{'loss': 7.918, 'ndcg_at_40': 0.3797, 'val_loss': 8.5803, 'val_ndcg_at_40': 0.4021}\n",
      "{}\n",
      "{'loss': 7.7327, 'ndcg_at_40': 0.3761, 'val_loss': 8.8434, 'val_ndcg_at_40': 0.4063}\n",
      "{}\n",
      "{'loss': 8.1397, 'ndcg_at_40': 0.3711, 'val_loss': 8.8789, 'val_ndcg_at_40': 0.4037}\n",
      "{}\n",
      "{'loss': 8.0975, 'ndcg_at_40': 0.3845, 'val_loss': 8.6396, 'val_ndcg_at_40': 0.3984}\n",
      "{}\n",
      "{'loss': 8.008, 'ndcg_at_40': 0.3785, 'val_loss': 8.9605, 'val_ndcg_at_40': 0.404}\n",
      "{}\n",
      "{'loss': 8.3218, 'ndcg_at_40': 0.3867, 'val_loss': 8.9611, 'val_ndcg_at_40': 0.4008}\n",
      "{}\n",
      "{'loss': 8.3012, 'ndcg_at_40': 0.3808, 'val_loss': 8.7959, 'val_ndcg_at_40': 0.3929}\n",
      "{}\n",
      "{'loss': 8.217, 'ndcg_at_40': 0.3741, 'val_loss': 9.0505, 'val_ndcg_at_40': 0.4004}\n",
      "{}\n",
      "{'loss': 8.3171, 'ndcg_at_40': 0.3804, 'val_loss': 9.2196, 'val_ndcg_at_40': 0.4093}\n",
      "{}\n",
      "{'loss': 8.5339, 'ndcg_at_40': 0.3814, 'val_loss': 9.1211, 'val_ndcg_at_40': 0.4107}\n",
      "{}\n",
      "{'loss': 8.3243, 'ndcg_at_40': 0.3858, 'val_loss': 9.3975, 'val_ndcg_at_40': 0.4069}\n",
      "{}\n",
      "{'loss': 8.5924, 'ndcg_at_40': 0.3897, 'val_loss': 9.273, 'val_ndcg_at_40': 0.404}\n",
      "{}\n",
      "{'loss': 8.6454, 'ndcg_at_40': 0.3886, 'val_loss': 9.4439, 'val_ndcg_at_40': 0.4039}\n",
      "{}\n",
      "{'loss': 8.6728, 'ndcg_at_40': 0.3891, 'val_loss': 9.4059, 'val_ndcg_at_40': 0.396}\n",
      "{}\n",
      "{'loss': 8.629, 'ndcg_at_40': 0.3885, 'val_loss': 9.6046, 'val_ndcg_at_40': 0.4013}\n",
      "{}\n",
      "{'loss': 8.8791, 'ndcg_at_40': 0.3911, 'val_loss': 9.7495, 'val_ndcg_at_40': 0.4074}\n",
      "{}\n",
      "{'loss': 8.9841, 'ndcg_at_40': 0.3864, 'val_loss': 9.5327, 'val_ndcg_at_40': 0.4092}\n",
      "{}\n",
      "{'loss': 8.8173, 'ndcg_at_40': 0.3858, 'val_loss': 9.8575, 'val_ndcg_at_40': 0.41}\n",
      "{}\n",
      "{'loss': 9.1521, 'ndcg_at_40': 0.3873, 'val_loss': 9.9683, 'val_ndcg_at_40': 0.4102}\n",
      "{}\n",
      "{'loss': 9.1844, 'ndcg_at_40': 0.3897, 'val_loss': 10.0307, 'val_ndcg_at_40': 0.4097}\n",
      "{}\n",
      "{'loss': 9.2146, 'ndcg_at_40': 0.3994, 'val_loss': 10.2523, 'val_ndcg_at_40': 0.408}\n",
      "{}\n",
      "{'loss': 9.4433, 'ndcg_at_40': 0.3914, 'val_loss': 10.0214, 'val_ndcg_at_40': 0.4059}\n",
      "{}\n",
      "{'loss': 9.442, 'ndcg_at_40': 0.3927, 'val_loss': 10.0355, 'val_ndcg_at_40': 0.4083}\n",
      "{}\n",
      "{'loss': 9.3851, 'ndcg_at_40': 0.3926, 'val_loss': 10.1278, 'val_ndcg_at_40': 0.4116}\n",
      "{}\n",
      "{'loss': 9.4377, 'ndcg_at_40': 0.3943, 'val_loss': 10.2364, 'val_ndcg_at_40': 0.4045}\n",
      "{}\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "v cannot be empty",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0d64ac51b36a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Success_at_4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mval_success\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_Success_at_4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m#plt.plot(val_success, label=recommender['model_name'] + \"val_sps\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-e7481e899a1a>\u001b[0m in \u001b[0;36mmoving_average\u001b[0;34m(x, w)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmoving_average\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(a, v, mode)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'a cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'v cannot be empty'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_mode_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: v cannot be empty"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1152x648 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_metric(metric_history, metric_name):\n",
    "    result = []\n",
    "    for item in metric_history:\n",
    "        try:\n",
    "            result.append(item[metric_name])\n",
    "        except:\n",
    "            print(item)\n",
    "    return result\n",
    "\n",
    "plt.figure(figsize=(16, 9))\n",
    "for recommender in data:\n",
    "    if len(recommender['metrics_history']) > 0:\n",
    "        history = recommender['metrics_history']\n",
    "        ndcg = get_metric(history, 'ndcg_at_40')\n",
    "        val_ndcg = moving_average(get_metric(history, 'val_ndcg_at_40'), 1)\n",
    "        \n",
    "        success = get_metric(history, 'Success_at_4')\n",
    "        val_success = moving_average(get_metric(history, 'val_Success_at_4'), 5)\n",
    "        \n",
    "        #plt.plot(val_success, label=recommender['model_name'] + \"val_sps\")\n",
    "        #plt.plot(success, label=recommender['model_name'] + \"sps\")\n",
    "        \n",
    "        plt.plot(val_ndcg, label=recommender['model_name'] + \"val_ndcg\")\n",
    "        plt.plot(ndcg, label=recommender['model_name'] + \"ndcg\")\n",
    "        #plt.plot(val_success, label=recommender['model_name'] + \"_val_sps\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(val_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['SPS@4'], df['ndcg@40'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
